{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MLearner's documentation! MLearner is a Python library of useful tools for the day-to-day data science tasks. Links Documentation: https://jaisenbe58r.github.io/MLearner/ Source code repository: https://github.com/jaisenbe58r/MLearner PyPI: https://pypi.python.org/pypi/mlearner Questions? Check out the Discord group MLearner Examples License MIT License Copyright (c) 2020 Jaime Sendra Berenguer Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Contact I received a lot of feedback and questions about mlearner recently, and I thought that it would be worthwhile to set up a public communication channel. Before you write an email with a question about mlearner, please consider posting it here since it can also be useful to others! Please join the Discord group MLearner If Google Groups is not for you, please feel free to write me an email or consider filing an issue on GitHub's issue tracker for new feature requests or bug reports. In addition, I setup a Gitter channel for live discussions.","title":"Home"},{"location":"#welcome-to-mlearners-documentation","text":"MLearner is a Python library of useful tools for the day-to-day data science tasks.","title":"Welcome to MLearner's documentation!"},{"location":"#links","text":"Documentation: https://jaisenbe58r.github.io/MLearner/ Source code repository: https://github.com/jaisenbe58r/MLearner PyPI: https://pypi.python.org/pypi/mlearner Questions? Check out the Discord group MLearner","title":"Links"},{"location":"#examples","text":"","title":"Examples"},{"location":"#license","text":"MIT License Copyright (c) 2020 Jaime Sendra Berenguer Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"#contact","text":"I received a lot of feedback and questions about mlearner recently, and I thought that it would be worthwhile to set up a public communication channel. Before you write an email with a question about mlearner, please consider posting it here since it can also be useful to others! Please join the Discord group MLearner If Google Groups is not for you, please feel free to write me an email or consider filing an issue on GitHub's issue tracker for new feature requests or bug reports. In addition, I setup a Gitter channel for live discussions.","title":"Contact"},{"location":"CHANGELOG/","text":"Release Notes The CHANGELOG for the current development version is available at https://github.com/jaisenbe58r/MLearner/blob/master/docs/sources/CHANGELOG.md . Version 0.18.0 (TBD) Downloads Source code (zip) Source code (tar.gz) New Features - Changes Implemented both use_clones and fit_base_estimators (previously refit in EnsembleVoteClassifier ) for EnsembleVoteClassifier and StackingClassifier . ( #670 via Katrina Ni ) Bug Fixes Fix axis DeprecationWarning in matplotlib v3.1.0 and newer. ( #673 ) Version 0.17.2 (02-24-2020) Downloads Source code (zip) Source code (tar.gz) New Features - Changes The previously deprecated OnehotTransactions has been removed in favor of the TransactionEncoder. Removed SparseDataFrame support in frequent pattern mining functions in favor of pandas >=1.0's new way for working sparse data. If you used SparseDataFrame formats, please see pandas' migration guide at https://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating. ( #667 ) The plot_confusion_matrix.py now also accepts a matplotlib figure and axis as input to which the confusion matrix plot can be added. ( #671 via Vahid Mirjalili ) Bug Fixes - Version 0.17.1 (2020-01-28) Downloads Source code (zip) Source code (tar.gz) New Features The SequentialFeatureSelector now supports using pre-specified feature sets via the fixed_features parameter. ( #578 ) Adds a new accuracy_score function to mlearner.evaluate for computing basic classifcation accuracy, per-class accuracy, and average per-class accuracy. ( #624 via Deepan Das ) StackingClassifier and StackingCVClassifier now have a decision_function method, which serves as a preferred choice over predict_proba in calculating roc_auc and average_precision scores when the meta estimator is a linear model or support vector classifier. ( #634 via Qiang Gu ) Changes Improve the runtime performance for the apriori frequent itemset generating function when low_memory=True . Setting low_memory=False (default) is still faster for small itemsets, but low_memory=True can be much faster for large itemsets and requires less memory. Also, input validation for apriori , \u0300 fpgrowth and fpmax takes a significant amount of time when input pandas DataFrame is large; this is now dramatically reduced when input contains boolean values (and not zeros/ones), which is the case when using TransactionEncoder`. ( #619 via Denis Barbier ) Add support for newer sparse pandas DataFrame for frequent itemset algorithms. Also, input validation for apriori , \u0300 fpgrowth and fpmax` runs much faster on sparse DataFrame when input pandas DataFrame contains integer values. ( #621 via Denis Barbier ) Let fpgrowth and fpmax directly work on sparse DataFrame, they were previously converted into dense Numpy arrays. ( #622 via Denis Barbier ) Bug Fixes Fixes a bug in mlearner.plotting.plot_pca_correlation_graph that caused the explaind variances not summing up to 1. Also, improves the runtime performance of the correlation computation and adds a missing function argument for the explained variances (eigenvalues) if users provide their own principal components. ( #593 via Gabriel Azevedo Ferreira ) Behavior of fpgrowth and apriori consistent for edgecases such as min_support=0 . ( #573 via Steve Harenberg ) fpmax returns an empty data frame now instead of raising an error if the frequent itemset set is empty. ( #573 via Steve Harenberg ) Fixes and issue in mlearner.plotting.plot_confusion_matrix , where the font-color choice for medium-dark cells was not ideal and hard to read. #588 via sohrabtowfighi ) The svd mode of mlearner.feature_extraction.PrincipalComponentAnalysis now also n-1 degrees of freedom instead of n d.o.f. when computing the eigenvalues to match the behavior of eigen . #595 Disable input validation for StackingCVClassifier because it causes issues if pipelines are used as input. #606 Version 0.17.0 (07/19/2019) Downloads Source code (zip) Source code (tar.gz) New Features Added an enhancement to the existing iris_data() such that both the UCI Repository version of the Iris dataset as well as the corrected, original version of the dataset can be loaded, which has a slight difference in two data points (consistent with Fisher's paper; this is also the same as in R). (via #539 via janismdhanbad ) Added optional groups parameter to SequentialFeatureSelector and ExhaustiveFeatureSelector fit() methods for forwarding to sklearn CV ( #537 via arc12 ) Added a new plot_pca_correlation_graph function to the mlearner.plotting submodule for plotting a PCA correlation graph. ( #544 via Gabriel-Azevedo-Ferreira ) Added a zoom_factor parameter to the mlxten.plotting.plot_decision_region function that allows users to zoom in and out of the decision region plots. ( #545 ) Added a function fpgrowth that implements the FP-Growth algorithm for mining frequent itemsets as a drop-in replacement for the existing apriori algorithm. ( #550 via Steve Harenberg ) New heatmap function in mlearner.plotting . ( #552 ) Added a function fpmax that implements the FP-Max algorithm for mining maximal itemsets as a drop-in replacement for the fpgrowth algorithm. ( #553 via Steve Harenberg ) New figsize parameter for the plot_decision_regions function in mlearner.plotting . ( #555 via Mirza Hasanbasic ) New low_memory option for the apriori frequent itemset generating function. Setting low_memory=False (default) uses a substantially optimized version of the algorithm that is 3-6x faster than the original implementation ( low_memory=True ). ( #567 via jmayse ) Added numerically stable OLS methods which uses QR decomposition and Singular Value Decomposition (SVD) methods to LinearRegression in mlearner.regressor.linear_regression . ( #575 via PuneetGrov3r ) Changes Now uses the latest joblib library under the hood for multiprocessing instead of sklearn.externals.joblib . ( #547 ) Changes to StackingCVClassifier and StackingCVRegressor such that first-level models are allowed to generate output of non-numeric type. ( #562 ) Bug Fixes Fixed documentation of iris_data() under iris.py by adding a note about differences in the iris data in R and UCI machine learning repo. Make sure that if the 'svd' mode is used in PCA, the number of eigenvalues is the same as when using 'eigen' (append 0's zeros in that case) ( #565 ) Version 0.16.0 (05/12/2019) Downloads Source code (zip) Source code (tar.gz) New Features StackingCVClassifier and StackingCVRegressor now support random_state parameter, which, together with shuffle , controls the randomness in the cv splitting. ( #523 via Qiang Gu ) StackingCVClassifier and StackingCVRegressor now have a new drop_last_proba parameter. It drops the last \"probability\" column in the feature set since if True , because it is redundant: p(y_c) = 1 - p(y_1) + p(y_2) + ... + p(y_{c-1}). This can be useful for meta-classifiers that are sensitive to perfectly collinear features. ( #532 ) Other stacking estimators, including StackingClassifier , StackingCVClassifier and StackingRegressor , support grid search over the regressors and even a single base regressor. ( #522 via Qiang Gu ) Adds multiprocessing support to StackingCVClassifier . ( #522 via Qiang Gu ) Adds multiprocessing support to StackingCVRegressor . ( #512 via Qiang Gu ) Now, the StackingCVRegressor also enables grid search over the regressors and even a single base regressor. When there are level-mixed parameters, GridSearchCV will try to replace hyperparameters in a top-down order (see the documentation for examples details). ( #515 via Qiang Gu ) Adds a verbose parameter to apriori to show the current iteration number as well as the itemset size currently being sampled. ( #519 Adds an optional class_name parameter to the confusion matrix function to display class names on the axis as tick marks. ( #487 via sandpiturtle ) Adds a pca.e_vals_normalized_ attribute to PCA for storing the eigenvalues also in normalized form; this is commonly referred to as variance explained ratios. #545 Changes Due to new features, restructuring, and better scikit-learn support (for GridSearchCV , etc.) the StackingCVRegressor 's meta regressor is now being accessed via 'meta_regressor__* in the parameter grid. E.g., if a RandomForestRegressor as meta- egressor was previously tuned via 'randomforestregressor__n_estimators' , this has now changed to 'meta_regressor__n_estimators' . ( #515 via Qiang Gu ) The same change mentioned above is now applied to other stacking estimators, including StackingClassifier , StackingCVClassifier and StackingRegressor . ( #522 via Qiang Gu ) Automatically performs mean centering for PCA solver 'SVD' such that using SVD is always equal to using the covariance matrix approach #545 Bug Fixes The feature_selection.ColumnSelector now also supports column names of type int (in addition to str names) if the input is a pandas DataFrame. ( #500 via tetrar124 Fix unreadable labels in plot_confusion_matrix for imbalanced datasets if show_absolute=True and show_normed=True . ( #504 ) Raises a more informative error if a SparseDataFrame is passed to apriori and the dataframe has integer column names that don't start with 0 due to current limitations of the SparseDataFrame implementation in pandas. ( #503 ) SequentialFeatureSelector now supports DataFrame as input for all operating modes (forward/backward/floating). #506 mlearner.evaluate.feature_importance_permutation now correctly accepts scoring functions with proper function signature as metric argument. #528 Version 0.15.0 (01-19-2019) Downloads Source code (zip) Source code (tar.gz) New Features Adds a new transformer class to mlearner.image , EyepadAlign , that aligns face images based on the location of the eyes. ( #466 by Vahid Mirjalili ) Adds a new function, mlearner.evaluate.bias_variance_decomp that decomposes the loss of a regressor or classifier into bias and variance terms. ( #470 ) Adds a whitening parameter to PrincipalComponentAnalysis , to optionally whiten the transformed data such that the features have unit variance. ( #475 ) Changes Changed the default solver in PrincipalComponentAnalysis to 'svd' instead of 'eigen' to improve numerical stability. ( #474 ) The mlearner.image.extract_face_landmarks now returns None if no facial landmarks were detected instead of an array of all zeros. ( #466 ) Bug Fixes The eigenvectors maybe have not been sorted in certain edge cases if solver was 'eigen' in PrincipalComponentAnalysis and LinearDiscriminantAnalysis . ( #477 , #478 ) Version 0.14.0 (11-09-2018) Downloads Source code (zip) Source code (tar.gz) New Features Added a scatterplotmatrix function to the plotting module. ( #437 ) Added sample_weight option to StackingRegressor , StackingClassifier , StackingCVRegressor , StackingCVClassifier , EnsembleVoteClassifier . ( #438 ) Added a RandomHoldoutSplit class to perform a random train/valid split without rotation in SequentialFeatureSelector , scikit-learn GridSearchCV etc. ( #442 ) Added a PredefinedHoldoutSplit class to perform a train/valid split, based on user-specified indices, without rotation in SequentialFeatureSelector , scikit-learn GridSearchCV etc. ( #443 ) Created a new mlearner.image submodule for working on image processing-related tasks. ( #457 ) Added a new convenience function extract_face_landmarks based on dlib to mlearner.image . ( #458 ) Added a method='oob' option to the mlearner.evaluate.bootstrap_point632_score method to compute the classic out-of-bag bootstrap estimate ( #459 ) Added a method='.632+' option to the mlearner.evaluate.bootstrap_point632_score method to compute the .632+ bootstrap estimate that addresses the optimism bias of the .632 bootstrap ( #459 ) Added a new mlearner.evaluate.ftest function to perform an F-test for comparing the accuracies of two or more classification models. ( #460 ) Added a new mlearner.evaluate.combined_ftest_5x2cv function to perform an combined 5x2cv F-Test for comparing the performance of two models. ( #461 ) Added a new mlearner.evaluate.difference_proportions test for comparing two proportions (e.g., classifier accuracies) ( #462 ) Changes Addressed deprecations warnings in NumPy 0.15. ( #425 ) Because of complications in PR ( #459 ), Python 2.7 was now dropped; since official support for Python 2.7 by the Python Software Foundation is ending in approx. 12 months anyways, this re-focussing will hopefully free up some developer time with regard to not having to worry about backward compatibility Bug Fixes Fixed an issue with a missing import in mlearner.plotting.plot_confusion_matrix . ( #428 ) Version 0.13.0 (2018-07-20) Downloads Source code (zip) Source code (tar.gz) New Features A meaningful error message is now raised when a cross-validation generator is used with SequentialFeatureSelector . ( #377 ) The SequentialFeatureSelector now accepts custom feature names via the fit method for more interpretable feature subset reports. ( #379 ) The SequentialFeatureSelector is now also compatible with Pandas DataFrames and uses DataFrame column-names for more interpretable feature subset reports. ( #379 ) ColumnSelector now works with Pandas DataFrames columns. ( #378 by Manuel Garrido ) The ExhaustiveFeatureSelector estimator in mlearner.feature_selection now is safely stoppable mid-process by control+c. ( #380 ) Two new functions, vectorspace_orthonormalization and vectorspace_dimensionality were added to mlearner.math to use the Gram-Schmidt process to convert a set of linearly independent vectors into a set of orthonormal basis vectors, and to compute the dimensionality of a vectorspace, respectively. ( #382 ) mlearner.frequent_patterns.apriori now supports pandas SparseDataFrame s to generate frequent itemsets. ( #404 via Daniel Morales ) The plot_confusion_matrix function now has the ability to show normalized confusion matrix coefficients in addition to or instead of absolute confusion matrix coefficients with or without a colorbar. The text display method has been changed so that the full range of the colormap is used. The default size is also now set based on the number of classes. Added support for merging the meta features with the original input features in StackingRegressor (via use_features_in_secondary ) like it is already supported in the other Stacking classes. ( #418 ) Added a support_only to the association_rules function, which allow constructing association rules (based on the support metric only) for cropped input DataFrames that don't contain a complete set of antecedent and consequent support values. ( #421 ) Changes Itemsets generated with apriori are now frozenset s ( #393 by William Laney and #394 ) Now raises an error if a input DataFrame to apriori contains non 0, 1, True, False values. #419 ) Bug Fixes Allow mlearner estimators to be cloned via scikit-learn's clone function. ( #374 ) Fixes bug to allow the correct use of refit=False in StackingRegressor and StackingCVRegressor ( #384 and ( #385 ) by selay01 ) Allow StackingClassifier to work with sparse matrices when use_features_in_secondary=True ( #408 by Floris Hoogenbook ) Allow StackingCVRegressor to work with sparse matrices when use_features_in_secondary=True ( #416 ) Allow StackingCVClassifier to work with sparse matrices when use_features_in_secondary=True ( #417 ) Version 0.12.0 (2018-21-04) Downloads Source code (zip) Source code (tar.gz) New Features A new feature_importance_permuation function to compute the feature importance in classifiers and regressors via the permutation importance method ( #358 ) The fit method of the ExhaustiveFeatureSelector now optionally accepts **fit_params for the estimator that is used for the feature selection. ( #354 by Zach Griffith) The fit method of the SequentialFeatureSelector now optionally accepts **fit_params for the estimator that is used for the feature selection. ( #350 by Zach Griffith) Changes Replaced plot_decision_regions colors by a colorblind-friendly palette and adds contour lines for decision regions. ( #348 ) All stacking estimators now raise NonFittedErrors if any method for inference is called prior to fitting the estimator. ( #353 ) Renamed the refit parameter of both the StackingClassifier and StackingCVClassifier to use_clones to be more explicit and less misleading. ( #368 ) Bug Fixes Various changes in the documentation and documentation tools to fix formatting issues ( #363 ) Fixes a bug where the StackingCVClassifier 's meta features were not stored in the original order when shuffle=True ( #370 ) Many documentation improvements, including links to the User Guides in the API docs ( #371 ) Version 0.11.0 (2018-03-14) Downloads Source code (zip) Source code (tar.gz) New Features New function implementing the resampled paired t-test procedure ( paired_ttest_resampled ) to compare the performance of two models. ( #323 ) New function implementing the k-fold paired t-test procedure ( paired_ttest_kfold_cv ) to compare the performance of two models (also called k-hold-out paired t-test). ( #324 ) New function implementing the 5x2cv paired t-test procedure ( paired_ttest_5x2cv ) proposed by Dieterrich (1998) to compare the performance of two models. ( #325 ) A refit parameter was added to stacking classes (similar to the refit parameter in the EnsembleVoteClassifier ), to support classifiers and regressors that follow the scikit-learn API but are not compatible with scikit-learn's clone function. ( #322 ) The ColumnSelector now has a drop_axis argument to use it in pipelines with CountVectorizers . ( #333 ) Changes Raises an informative error message if predict or predict_meta_features is called prior to calling the fit method in StackingRegressor and StackingCVRegressor . ( #315 ) The plot_decision_regions function now automatically determines the optimal setting based on the feature dimensions and supports anti-aliasing. The old res parameter has been deprecated. ( #309 by Guillaume Poirier-Morency ) Apriori code is faster due to optimization in onehot transformation and the amount of candidates generated by the apriori algorithm. ( #327 by Jakub Smid ) The OnehotTransactions class (which is typically often used in combination with the apriori function for association rule mining) is now more memory efficient as it uses boolean arrays instead of integer arrays. In addition, the OnehotTransactions class can be now be provided with sparse argument to generate sparse representations of the onehot matrix to further improve memory efficiency. ( #328 by Jakub Smid ) The OneHotTransactions has been deprecated and replaced by the TransactionEncoder . ( #332 The plot_decision_regions function now has three new parameters, scatter_kwargs , contourf_kwargs , and scatter_highlight_kwargs , that can be used to modify the plotting style. ( #342 by James Bourbeau ) Bug Fixes Fixed issue when class labels were provided to the EnsembleVoteClassifier when refit was set to false . ( #322 ) Allow arrays with 16-bit and 32-bit precision in plot_decision_regions function. ( #337 ) Fixed bug that raised an indexing error if the number of items was <= 1 when computing association rules using the conviction metric. ( #340 ) Version 0.10.0 (2017-12-22) Downloads Source code (zip) Source code (tar.gz) New Features New store_train_meta_features parameter for fit in StackingCVRegressor. if True, train meta-features are stored in self.train_meta_features_ . New pred_meta_features method for StackingCVRegressor . People can get test meta-features using this method. ( #294 via takashioya ) The new store_train_meta_features attribute and pred_meta_features method for the StackingCVRegressor were also added to the StackingRegressor , StackingClassifier , and StackingCVClassifier ( #299 & #300 ) New function ( evaluate.mcnemar_tables ) for creating multiple 2x2 contigency from model predictions arrays that can be used in multiple McNemar (post-hoc) tests or Cochran's Q or F tests, etc. ( #307 ) New function ( evaluate.cochrans_q ) for performing Cochran's Q test to compare the accuracy of multiple classifiers. ( #310 ) Changes Added requirements.txt to setup.py . ( #304 via Colin Carrol ) Bug Fixes Improved numerical stability for p-values computed via the the exact McNemar test ( #306 ) nose is not required to use the library ( #302 ) Version 0.9.1 (2017-11-19) Downloads Source code (zip) Source code (tar.gz) New Features Added mlearner.evaluate.bootstrap_point632_score to evaluate the performance of estimators using the .632 bootstrap. ( #283 ) New max_len parameter for the frequent itemset generation via the apriori function to allow for early stopping. ( #270 ) Changes All feature index tuples in SequentialFeatureSelector or now in sorted order. ( #262 ) The SequentialFeatureSelector now runs the continuation of the floating inclusion/exclusion as described in Novovicova & Kittler (1994). Note that this didn't cause any difference in performance on any of the test scenarios but could lead to better performance in certain edge cases. ( #262 ) utils.Counter now accepts a name variable to help distinguish between multiple counters, time precision can be set with the 'precision' kwarg and the new attribute end_time holds the time the last iteration completed. ( #278 via Mathew Savage ) Bug Fixes Fixed an deprecation error that occured with McNemar test when using SciPy 1.0. ( #283 ) Version 0.9.0 (2017-10-21) Downloads Source code (zip) Source code (tar.gz) New Features Added evaluate.permutation_test , a permutation test for hypothesis testing (or A/B testing) to test if two samples come from the same distribution. Or in other words, a procedure to test the null hypothesis that that two groups are not significantly different (e.g., a treatment and a control group). ( #250 ) Added 'leverage' and 'conviction as evaluation metrics to the frequent_patterns.association_rules function. ( #246 & #247 ) Added a loadings_ attribute to PrincipalComponentAnalysis to compute the factor loadings of the features on the principal components. ( #251 ) Allow grid search over classifiers/regressors in ensemble and stacking estimators. ( #259 ) New make_multiplexer_dataset function that creates a dataset generated by a n-bit Boolean multiplexer for evaluating supervised learning algorithms. ( #263 ) Added a new BootstrapOutOfBag class, an implementation of the out-of-bag bootstrap to evaluate supervised learning algorithms. ( #265 ) The parameters for StackingClassifier , StackingCVClassifier , StackingRegressor , StackingCVRegressor , and EnsembleVoteClassifier can now be tuned using scikit-learn's GridSearchCV ( #254 via James Bourbeau ) Changes The 'support' column returned by frequent_patterns.association_rules was changed to compute the support of \"antecedant union consequent\", and new antecedant support' and 'consequent support' column were added to avoid ambiguity. ( #245 ) Allow the OnehotTransactions to be cloned via scikit-learn's clone function, which is required by e.g., scikit-learn's FeatureUnion or GridSearchCV (via Iaroslav Shcherbatyi ). ( #249 ) Bug Fixes Fix issues with self._init_time parameter in _IterativeModel subclasses. ( #256 ) Fix imprecision bug that occurred in plot_ecdf when run on Python 2.7. ( 264 ) The vectors from SVD in PrincipalComponentAnalysis are now being scaled so that the eigenvalues via solver='eigen' and solver='svd' now store eigenvalues that have the same magnitudes. ( #251 ) Version 0.8.0 (2017-09-09) Downloads Source code (zip) Source code (tar.gz) New Features Added a mlearner.evaluate.bootstrap that implements the ordinary nonparametric bootstrap to bootstrap a single statistic (for example, the mean. median, R^2 of a regression fit, and so forth) #232 SequentialFeatureSelecor 's k_features now accepts a string argument \"best\" or \"parsimonious\" for more \"automated\" feature selection. For instance, if \"best\" is provided, the feature selector will return the feature subset with the best cross-validation performance. If \"parsimonious\" is provided as an argument, the smallest feature subset that is within one standard error of the cross-validation performance will be selected. #238 Changes SequentialFeatureSelector now uses np.nanmean over normal mean to support scorers that may return np.nan #211 (via mrkaiser ) The skip_if_stuck parameter was removed from SequentialFeatureSelector in favor of a more efficient implementation comparing the conditional inclusion/exclusion results (in the floating versions) to the performances of previously sampled feature sets that were cached #237 ExhaustiveFeatureSelector was modified to consume substantially less memory #195 (via Adam Erickson ) Bug Fixes Fixed a bug where the SequentialFeatureSelector selected a feature subset larger than then specified via the k_features tuple max-value #213 Version 0.7.0 (2017-06-22) Downloads Source code (zip) Source code (tar.gz) New Features New mlearner.plotting.ecdf function for plotting empirical cumulative distribution functions ( #196 ). New StackingCVRegressor for stacking regressors with out-of-fold predictions to prevent overfitting ( #201 via Eike Dehling ). Changes The TensorFlow estimator have been removed from mlearner, since TensorFlow has now very convenient ways to build on estimators, which render those implementations obsolete. plot_decision_regions now supports plotting decision regions for more than 2 training features #189 , via James Bourbeau ). Parallel execution in mlearner.feature_selection.SequentialFeatureSelector and mlearner.feature_selection.ExhaustiveFeatureSelector is now performed over different feature subsets instead of the different cross-validation folds to better utilize machines with multiple processors if the number of features is large ( #193 , via @whalebot-helmsman ). Raise meaningful error messages if pandas DataFrame s or Python lists of lists are fed into the StackingCVClassifer as a fit arguments ( 198 ). The n_folds parameter of the StackingCVClassifier was changed to cv and can now accept any kind of cross validation technique that is available from scikit-learn. For example, StackingCVClassifier(..., cv=StratifiedKFold(n_splits=3)) or StackingCVClassifier(..., cv=GroupKFold(n_splits=3)) ( #203 , via Konstantinos Paliouras ). Bug Fixes SequentialFeatureSelector now correctly accepts a None argument for the scoring parameter to infer the default scoring metric from scikit-learn classifiers and regressors ( #171 ). The plot_decision_regions function now supports pre-existing axes objects generated via matplotlib's plt.subplots . ( #184 , see example ) Made math.num_combinations and math.num_permutations numerically stable for large numbers of combinations and permutations ( #200 ). Version 0.6.0 (2017-03-18) Downloads Source code (zip) Source code (tar.gz) New Features An association_rules function is implemented that allows to generate rules based on a list of frequent itemsets (via Joshua Goerner ). Changes Adds a black edgecolor to plots via plotting.plot_decision_regions to make markers more distinguishable from the background in matplotlib>=2.0 . The association submodule was renamed to frequent_patterns . Bug Fixes The DataFrame index of apriori results are now unique and ordered. Fixed typos in autompg and wine datasets (via James Bourbeau ). Version 0.5.1 (2017-02-14) Downloads Source code (zip) Source code (tar.gz) New Features The EnsembleVoteClassifier has a new refit attribute that prevents refitting classifiers if refit=False to save computational time. Added a new lift_score function in evaluate to compute lift score (via Batuhan Bardak ). StackingClassifier and StackingRegressor support multivariate targets if the underlying models do (via kernc ). StackingClassifier has a new use_features_in_secondary attribute like StackingCVClassifier . Changes Changed default verbosity level in SequentialFeatureSelector to 0 The EnsembleVoteClassifier now raises a NotFittedError if the estimator wasn't fit before calling predict . (via Anton Loss ) Added new TensorFlow variable initialization syntax to guarantee compatibility with TensorFlow 1.0 Bug Fixes Fixed wrong default value for k_features in SequentialFeatureSelector Cast selected feature subsets in the SequentialFeautureSelector as sets to prevent the iterator from getting stuck if the k_idx are different permutations of the same combination (via Zac Wellmer ). Fixed an issue with learning curves that caused the performance metrics to be reversed (via ipashchenko ) Fixed a bug that could occur in the SequentialFeatureSelector if there are similarly-well performing subsets in the floating variants (via Zac Wellmer ). Version 0.5.0 (2016-11-09) Downloads Source code (zip) Source code (tar.gz) New Features New ExhaustiveFeatureSelector estimator in mlearner.feature_selection for evaluating all feature combinations in a specified range The StackingClassifier has a new parameter average_probas that is set to True by default to maintain the current behavior. A deprecation warning was added though, and it will default to False in future releases (0.6.0); average_probas=False will result in stacking of the level-1 predicted probabilities rather than averaging these. New StackingCVClassifier estimator in 'mlearner.classifier' for implementing a stacking ensemble that uses cross-validation techniques for training the meta-estimator to avoid overfitting ( Reiichiro Nakano ) New OnehotTransactions encoder class added to the preprocessing submodule for transforming transaction data into a one-hot encoded array The SequentialFeatureSelector estimator in mlearner.feature_selection now is safely stoppable mid-process by control+c, and deprecated print_progress in favor of a more tunable verbose parameter ( Will McGinnis ) New apriori function in association to extract frequent itemsets from transaction data for association rule mining New checkerboard_plot function in plotting to plot checkerboard tables / heat maps New mcnemar_table and mcnemar functions in evaluate to compute 2x2 contingency tables and McNemar's test Changes All plotting functions have been moved to mlearner.plotting for compatibility reasons with continuous integration services and to make the installation of matplotlib optional for users of mlearner 's core functionality Added a compatibility layer for scikit-learn 0.18 using the new model_selection module while maintaining backwards compatibility to scikit-learn 0.17. Bug Fixes mlearner.plotting.plot_decision_regions now draws decision regions correctly if more than 4 class labels are present Raise AttributeError in plot_decision_regions when the X_higlight argument is a 1D array ( chkoar ) Version 0.4.2 (2016-08-24) Downloads Source code (zip) Source code (tar.gz) PDF documentation New Features Added preprocessing.CopyTransformer , a mock class that returns copies of imput arrays via transform and fit_transform Changes Added AppVeyor to CI to ensure MS Windows compatibility Dataset are now saved as compressed .txt or .csv files rather than being imported as Python objects feature_selection.SequentialFeatureSelector now supports the selection of k_features using a tuple to specify a \"min-max\" k_features range Added \"SVD solver\" option to the PrincipalComponentAnalysis Raise a AttributeError with \"not fitted\" message in SequentialFeatureSelector if transform or get_metric_dict are called prior to fit Use small, positive bias units in TfMultiLayerPerceptron 's hidden layer(s) if the activations are ReLUs in order to avoid dead neurons Added an optional clone_estimator parameter to the SequentialFeatureSelector that defaults to True , avoiding the modification of the original estimator objects More rigorous type and shape checks in the evaluate.plot_decision_regions function DenseTransformer now doesn't raise and error if the input array is not sparse API clean-up using scikit-learn's BaseEstimator as parent class for feature_selection.ColumnSelector Bug Fixes Fixed a problem when a tuple-range was provided as argument to the SequentialFeatureSelector 's k_features parameter and the scoring metric was more negative than -1 (e.g., as in scikit-learn's MSE scoring function) (wahutch](https://github.com/wahutch)) Fixed an AttributeError issue when verbose > 1 in StackingClassifier Fixed a bug in classifier.SoftmaxRegression where the mean values of the offsets were used to update the bias units rather than their sum Fixed rare bug in MLP _layer_mapping functions that caused a swap between the random number generation seed when initializing weights and biases Version 0.4.1 (2016-05-01) Downloads Source code (zip) Source code (tar.gz) PDF documentation New Features New TensorFlow estimator for Linear Regression ( tf_regressor.TfLinearRegression ) New k-means clustering estimator ( cluster.Kmeans ) New TensorFlow k-means clustering estimator ( tf_cluster.Kmeans ) Changes Due to refactoring of the estimator classes, the init_weights parameter of the fit methods was globally renamed to init_params Overall performance improvements of estimators due to code clean-up and refactoring Added several additional checks for correct array types and more meaningful exception messages Added optional dropout to the tf_classifier.TfMultiLayerPerceptron classifier for regularization Added an optional decay parameter to the tf_classifier.TfMultiLayerPerceptron classifier for adaptive learning via an exponential decay of the learning rate eta Replaced old NeuralNetMLP by more streamlined MultiLayerPerceptron ( classifier.MultiLayerPerceptron ); now also with softmax in the output layer and categorical cross-entropy loss. Unified init_params parameter for fit functions to continue training where the algorithm left off (if supported) Version 0.4.0 (2016-04-09) New Features New TfSoftmaxRegression classifier using Tensorflow ( tf_classifier.TfSoftmaxRegression ) New SoftmaxRegression classifier ( classifier.SoftmaxRegression ) New TfMultiLayerPerceptron classifier using Tensorflow ( tf_classifier.TfMultiLayerPerceptron ) New StackingRegressor ( regressor.StackingRegressor ) New StackingClassifier ( classifier.StackingClassifier ) New function for one-hot encoding of class labels ( preprocessing.one_hot ) Added GridSearch support to the SequentialFeatureSelector ( feature_selection/.SequentialFeatureSelector ) evaluate.plot_decision_regions improvements: Function now handles class y-class labels correctly if array is of type float Correct handling of input arguments markers and colors Accept an existing Axes via the ax argument New print_progress parameter for all generalized models and multi-layer neural networks for printing time elapsed, ETA, and the current cost of the current epoch Minibatch learning for classifier.LogisticRegression , classifier.Adaline , and regressor.LinearRegression plus streamlined API New Principal Component Analysis class via mlearner.feature_extraction.PrincipalComponentAnalysis New RBF Kernel Principal Component Analysis class via mlearner.feature_extraction.RBFKernelPCA New Linear Discriminant Analysis class via mlearner.feature_extraction.LinearDiscriminantAnalysis Changes The column parameter in mlearner.preprocessing.standardize now defaults to None to standardize all columns more conveniently Version 0.3.0 (2016-01-31) Downloads Source code (zip) Source code (tar.gz) New Features Added a progress bar tracker to classifier.NeuralNetMLP Added a function to score predicted vs. target class labels evaluate.scoring Added confusion matrix functions to create ( evaluate.confusion_matrix ) and plot ( evaluate.plot_confusion_matrix ) confusion matrices New style parameter and improved axis scaling in mlearner.evaluate.plot_learning_curves Added loadlocal_mnist to mlearner.data for streaming MNIST from a local byte files into numpy arrays New NeuralNetMLP parameters: random_weights , shuffle_init , shuffle_epoch New SFS features such as the generation of pandas DataFrame results tables and plotting functions (with confidence intervals, standard deviation, and standard error bars) Added support for regression estimators in SFS Added Boston housing dataset New shuffle parameter for classifier.NeuralNetMLP Changes The mlearner.preprocessing.standardize function now optionally returns the parameters, which are estimated from the array, for re-use. A further improvement makes the standardize function smarter in order to avoid zero-division errors Cosmetic improvements to the evaluate.plot_decision_regions function such as hiding plot axes Renaming of classifier.EnsembleClassfier to classifier.EnsembleVoteClassifier Improved random weight initialization in Perceptron , Adaline , LinearRegression , and LogisticRegression Changed learning parameter of mlearner.classifier.Adaline to solver and added \"normal equation\" as closed-form solution solver Hide y-axis labels in mlearner.evaluate.plot_decision_regions in 1 dimensional evaluations Sequential Feature Selection algorithms were unified into a single SequentialFeatureSelector class with parameters to enable floating selection and toggle between forward and backward selection. Stratified sampling of MNIST (now 500x random samples from each of the 10 digit categories) Renaming mlearner.plotting to mlearner.general_plotting in order to distinguish general plotting function from specialized utility function such as evaluate.plot_decision_regions Version 0.2.9 (2015-07-14) Downloads Source code (zip) Source code (tar.gz) New Features Sequential Feature Selection algorithms: SFS, SFFS, SBS, and SFBS Changes Changed regularization & lambda parameters in LogisticRegression to single parameter l2_lambda Version 0.2.8 (2015-06-27) API changes: mlearner.sklearn.EnsembleClassifier -> mlearner.classifier.EnsembleClassifier mlearner.sklearn.ColumnSelector -> mlearner.feature_selection.ColumnSelector mlearner.sklearn.DenseTransformer -> mlearner.preprocessing.DenseTransformer mlearner.pandas.standardizing -> mlearner.preprocessing.standardizing mlearner.pandas.minmax_scaling -> mlearner.preprocessing.minmax_scaling mlearner.matplotlib -> mlearner.plotting Added momentum learning parameter (alpha coefficient) to mlearner.classifier.NeuralNetMLP . Added adaptive learning rate (decrease constant) to mlearner.classifier.NeuralNetMLP . mlearner.pandas.minmax_scaling became mlearner.preprocessing.minmax_scaling and also supports NumPy arrays now mlearner.pandas.standardizing became mlearner.preprocessing.standardizing and now supports both NumPy arrays and pandas DataFrames; also, now ddof parameters to set the degrees of freedom when calculating the standard deviation Version 0.2.7 (2015-06-20) Added multilayer perceptron (feedforward artificial neural network) classifier as mlearner.classifier.NeuralNetMLP . Added 5000 labeled trainingsamples from the MNIST handwritten digits dataset to mlearner.data Version 0.2.6 (2015-05-08) Added ordinary least square regression using different solvers (gradient and stochastic gradient descent, and the closed form solution (normal equation) Added option for random weight initialization to logistic regression classifier and updated l2 regularization Added wine dataset to mlearner.data Added invert_axes parameter mlearner.matplotlib.enrichtment_plot to optionally plot the \"Count\" on the x-axis New verbose parameter for mlearner.sklearn.EnsembleClassifier by Alejandro C. Bahnsen Added mlearner.pandas.standardizing to standardize columns in a Pandas DataFrame Added parameters linestyles and markers to mlearner.matplotlib.enrichment_plot mlearner.regression.lin_regplot automatically adds np.newaxis and works w. python lists Added tokenizers: mlearner.text.extract_emoticons and mlearner.text.extract_words_and_emoticons Version 0.2.5 (2015-04-17) Added Sequential Backward Selection (mlearner.sklearn.SBS) Added X_highlight parameter to mlearner.evaluate.plot_decision_regions for highlighting test data points. Added mlearner.regression.lin_regplot to plot the fitted line from linear regression. Added mlearner.matplotlib.stacked_barplot to conveniently produce stacked barplots using pandas DataFrame s. Added mlearner.matplotlib.enrichment_plot Version 0.2.4 (2015-03-15) Added scoring to mlearner.evaluate.learning_curves (by user pfsq) Fixed setup.py bug caused by the missing README.html file matplotlib.category_scatter for pandas DataFrames and Numpy arrays Version 0.2.3 (2015-03-11) Added Logistic regression Gradient descent and stochastic gradient descent perceptron was changed to Adaline (Adaptive Linear Neuron) Perceptron and Adaline for {0, 1} classes Added mlearner.preprocessing.shuffle_arrays_unison function to shuffle one or more NumPy arrays. Added shuffle and random seed parameter to stochastic gradient descent classifier. Added rstrip parameter to mlearner.file_io.find_filegroups to allow trimming of base names. Added ignore_substring parameter to mlearner.file_io.find_filegroups and find_files . Replaced .rstrip in mlearner.file_io.find_filegroups with more robust regex. Gridsearch support for mlearner.sklearn.EnsembleClassifier Version 0.2.2 (2015-03-01) Improved robustness of EnsembleClassifier. Extended plot_decision_regions() functionality for plotting 1D decision boundaries. Function matplotlib.plot_decision_regions was reorganized to evaluate.plot_decision_regions . evaluate.plot_learning_curves() function added. Added Rosenblatt, gradient descent, and stochastic gradient descent perceptrons. Version 0.2.1 (2015-01-20) Added mlearner.pandas.minmax_scaling - a function to rescale pandas DataFrame columns. Slight update to the EnsembleClassifier interface (additional voting parameter) Fixed EnsembleClassifier to return correct class labels if class labels are not integers from 0 to n. Added new matplotlib function to plot decision regions of classifiers. Version 0.2.0 (2015-01-13) Improved mlearner.text.generalize_duplcheck to remove duplicates and prevent endless looping issue. Added recursive search parameter to mlearner.file_io.find_files. Added check_ext parameter mlearner.file_io.find_files to search based on file extensions. Default parameter to ignore invisible files for mlearner.file_io.find. Added transform and fit_transform to the EnsembleClassifier . Added mlearner.file_io.find_filegroups function. Version 0.1.9 (2015-01-10) Implemented scikit-learn EnsembleClassifier (majority voting rule) class. Version 0.1.8 (2015-01-07) Improvements to mlearner.text.generalize_names to handle certain Dutch last name prefixes (van, van der, de, etc.). Added mlearner.text.generalize_name_duplcheck function to apply mlearner.text.generalize_names function to a pandas DataFrame without creating duplicates. Version 0.1.7 (2015-01-07) Added text utilities with name generalization function. Added and file_io utilities. Version 0.1.6 (2015-01-04) Added combinations and permutations estimators. Version 0.1.5 (2014-12-11) Added DenseTransformer for pipelines and grid search. Version 0.1.4 (2014-08-20) mean_centering function is now a Class that creates MeanCenterer objects that can be used to fit data via the fit method, and center data at the column means via the transform and fit_transform method. Version 0.1.3 (2014-08-19) Added preprocessing module and mean_centering function. Version 0.1.2 (2014-08-19) Added matplotlib utilities and remove_borders function. Version 0.1.1 (2014-08-13) Simplified code for ColumnSelector.","title":"Release Notes"},{"location":"CHANGELOG/#release-notes","text":"The CHANGELOG for the current development version is available at https://github.com/jaisenbe58r/MLearner/blob/master/docs/sources/CHANGELOG.md .","title":"Release Notes"},{"location":"CHANGELOG/#version-0180-tbd","text":"","title":"Version 0.18.0 (TBD)"},{"location":"CHANGELOG/#downloads","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features","text":"-","title":"New Features"},{"location":"CHANGELOG/#changes","text":"Implemented both use_clones and fit_base_estimators (previously refit in EnsembleVoteClassifier ) for EnsembleVoteClassifier and StackingClassifier . ( #670 via Katrina Ni )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes","text":"Fix axis DeprecationWarning in matplotlib v3.1.0 and newer. ( #673 )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-0172-02-24-2020","text":"","title":"Version 0.17.2 (02-24-2020)"},{"location":"CHANGELOG/#downloads_1","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_1","text":"-","title":"New Features"},{"location":"CHANGELOG/#changes_1","text":"The previously deprecated OnehotTransactions has been removed in favor of the TransactionEncoder. Removed SparseDataFrame support in frequent pattern mining functions in favor of pandas >=1.0's new way for working sparse data. If you used SparseDataFrame formats, please see pandas' migration guide at https://pandas.pydata.org/pandas-docs/stable/user_guide/sparse.html#migrating. ( #667 ) The plot_confusion_matrix.py now also accepts a matplotlib figure and axis as input to which the confusion matrix plot can be added. ( #671 via Vahid Mirjalili )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_1","text":"-","title":"Bug Fixes"},{"location":"CHANGELOG/#version-0171-2020-01-28","text":"","title":"Version 0.17.1 (2020-01-28)"},{"location":"CHANGELOG/#downloads_2","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_2","text":"The SequentialFeatureSelector now supports using pre-specified feature sets via the fixed_features parameter. ( #578 ) Adds a new accuracy_score function to mlearner.evaluate for computing basic classifcation accuracy, per-class accuracy, and average per-class accuracy. ( #624 via Deepan Das ) StackingClassifier and StackingCVClassifier now have a decision_function method, which serves as a preferred choice over predict_proba in calculating roc_auc and average_precision scores when the meta estimator is a linear model or support vector classifier. ( #634 via Qiang Gu )","title":"New Features"},{"location":"CHANGELOG/#changes_2","text":"Improve the runtime performance for the apriori frequent itemset generating function when low_memory=True . Setting low_memory=False (default) is still faster for small itemsets, but low_memory=True can be much faster for large itemsets and requires less memory. Also, input validation for apriori , \u0300 fpgrowth and fpmax takes a significant amount of time when input pandas DataFrame is large; this is now dramatically reduced when input contains boolean values (and not zeros/ones), which is the case when using TransactionEncoder`. ( #619 via Denis Barbier ) Add support for newer sparse pandas DataFrame for frequent itemset algorithms. Also, input validation for apriori , \u0300 fpgrowth and fpmax` runs much faster on sparse DataFrame when input pandas DataFrame contains integer values. ( #621 via Denis Barbier ) Let fpgrowth and fpmax directly work on sparse DataFrame, they were previously converted into dense Numpy arrays. ( #622 via Denis Barbier )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_2","text":"Fixes a bug in mlearner.plotting.plot_pca_correlation_graph that caused the explaind variances not summing up to 1. Also, improves the runtime performance of the correlation computation and adds a missing function argument for the explained variances (eigenvalues) if users provide their own principal components. ( #593 via Gabriel Azevedo Ferreira ) Behavior of fpgrowth and apriori consistent for edgecases such as min_support=0 . ( #573 via Steve Harenberg ) fpmax returns an empty data frame now instead of raising an error if the frequent itemset set is empty. ( #573 via Steve Harenberg ) Fixes and issue in mlearner.plotting.plot_confusion_matrix , where the font-color choice for medium-dark cells was not ideal and hard to read. #588 via sohrabtowfighi ) The svd mode of mlearner.feature_extraction.PrincipalComponentAnalysis now also n-1 degrees of freedom instead of n d.o.f. when computing the eigenvalues to match the behavior of eigen . #595 Disable input validation for StackingCVClassifier because it causes issues if pipelines are used as input. #606","title":"Bug Fixes"},{"location":"CHANGELOG/#version-0170-07192019","text":"","title":"Version 0.17.0 (07/19/2019)"},{"location":"CHANGELOG/#downloads_3","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_3","text":"Added an enhancement to the existing iris_data() such that both the UCI Repository version of the Iris dataset as well as the corrected, original version of the dataset can be loaded, which has a slight difference in two data points (consistent with Fisher's paper; this is also the same as in R). (via #539 via janismdhanbad ) Added optional groups parameter to SequentialFeatureSelector and ExhaustiveFeatureSelector fit() methods for forwarding to sklearn CV ( #537 via arc12 ) Added a new plot_pca_correlation_graph function to the mlearner.plotting submodule for plotting a PCA correlation graph. ( #544 via Gabriel-Azevedo-Ferreira ) Added a zoom_factor parameter to the mlxten.plotting.plot_decision_region function that allows users to zoom in and out of the decision region plots. ( #545 ) Added a function fpgrowth that implements the FP-Growth algorithm for mining frequent itemsets as a drop-in replacement for the existing apriori algorithm. ( #550 via Steve Harenberg ) New heatmap function in mlearner.plotting . ( #552 ) Added a function fpmax that implements the FP-Max algorithm for mining maximal itemsets as a drop-in replacement for the fpgrowth algorithm. ( #553 via Steve Harenberg ) New figsize parameter for the plot_decision_regions function in mlearner.plotting . ( #555 via Mirza Hasanbasic ) New low_memory option for the apriori frequent itemset generating function. Setting low_memory=False (default) uses a substantially optimized version of the algorithm that is 3-6x faster than the original implementation ( low_memory=True ). ( #567 via jmayse ) Added numerically stable OLS methods which uses QR decomposition and Singular Value Decomposition (SVD) methods to LinearRegression in mlearner.regressor.linear_regression . ( #575 via PuneetGrov3r )","title":"New Features"},{"location":"CHANGELOG/#changes_3","text":"Now uses the latest joblib library under the hood for multiprocessing instead of sklearn.externals.joblib . ( #547 ) Changes to StackingCVClassifier and StackingCVRegressor such that first-level models are allowed to generate output of non-numeric type. ( #562 )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_3","text":"Fixed documentation of iris_data() under iris.py by adding a note about differences in the iris data in R and UCI machine learning repo. Make sure that if the 'svd' mode is used in PCA, the number of eigenvalues is the same as when using 'eigen' (append 0's zeros in that case) ( #565 )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-0160-05122019","text":"","title":"Version 0.16.0 (05/12/2019)"},{"location":"CHANGELOG/#downloads_4","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_4","text":"StackingCVClassifier and StackingCVRegressor now support random_state parameter, which, together with shuffle , controls the randomness in the cv splitting. ( #523 via Qiang Gu ) StackingCVClassifier and StackingCVRegressor now have a new drop_last_proba parameter. It drops the last \"probability\" column in the feature set since if True , because it is redundant: p(y_c) = 1 - p(y_1) + p(y_2) + ... + p(y_{c-1}). This can be useful for meta-classifiers that are sensitive to perfectly collinear features. ( #532 ) Other stacking estimators, including StackingClassifier , StackingCVClassifier and StackingRegressor , support grid search over the regressors and even a single base regressor. ( #522 via Qiang Gu ) Adds multiprocessing support to StackingCVClassifier . ( #522 via Qiang Gu ) Adds multiprocessing support to StackingCVRegressor . ( #512 via Qiang Gu ) Now, the StackingCVRegressor also enables grid search over the regressors and even a single base regressor. When there are level-mixed parameters, GridSearchCV will try to replace hyperparameters in a top-down order (see the documentation for examples details). ( #515 via Qiang Gu ) Adds a verbose parameter to apriori to show the current iteration number as well as the itemset size currently being sampled. ( #519 Adds an optional class_name parameter to the confusion matrix function to display class names on the axis as tick marks. ( #487 via sandpiturtle ) Adds a pca.e_vals_normalized_ attribute to PCA for storing the eigenvalues also in normalized form; this is commonly referred to as variance explained ratios. #545","title":"New Features"},{"location":"CHANGELOG/#changes_4","text":"Due to new features, restructuring, and better scikit-learn support (for GridSearchCV , etc.) the StackingCVRegressor 's meta regressor is now being accessed via 'meta_regressor__* in the parameter grid. E.g., if a RandomForestRegressor as meta- egressor was previously tuned via 'randomforestregressor__n_estimators' , this has now changed to 'meta_regressor__n_estimators' . ( #515 via Qiang Gu ) The same change mentioned above is now applied to other stacking estimators, including StackingClassifier , StackingCVClassifier and StackingRegressor . ( #522 via Qiang Gu ) Automatically performs mean centering for PCA solver 'SVD' such that using SVD is always equal to using the covariance matrix approach #545","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_4","text":"The feature_selection.ColumnSelector now also supports column names of type int (in addition to str names) if the input is a pandas DataFrame. ( #500 via tetrar124 Fix unreadable labels in plot_confusion_matrix for imbalanced datasets if show_absolute=True and show_normed=True . ( #504 ) Raises a more informative error if a SparseDataFrame is passed to apriori and the dataframe has integer column names that don't start with 0 due to current limitations of the SparseDataFrame implementation in pandas. ( #503 ) SequentialFeatureSelector now supports DataFrame as input for all operating modes (forward/backward/floating). #506 mlearner.evaluate.feature_importance_permutation now correctly accepts scoring functions with proper function signature as metric argument. #528","title":"Bug Fixes"},{"location":"CHANGELOG/#version-0150-01-19-2019","text":"","title":"Version 0.15.0 (01-19-2019)"},{"location":"CHANGELOG/#downloads_5","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_5","text":"Adds a new transformer class to mlearner.image , EyepadAlign , that aligns face images based on the location of the eyes. ( #466 by Vahid Mirjalili ) Adds a new function, mlearner.evaluate.bias_variance_decomp that decomposes the loss of a regressor or classifier into bias and variance terms. ( #470 ) Adds a whitening parameter to PrincipalComponentAnalysis , to optionally whiten the transformed data such that the features have unit variance. ( #475 )","title":"New Features"},{"location":"CHANGELOG/#changes_5","text":"Changed the default solver in PrincipalComponentAnalysis to 'svd' instead of 'eigen' to improve numerical stability. ( #474 ) The mlearner.image.extract_face_landmarks now returns None if no facial landmarks were detected instead of an array of all zeros. ( #466 )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_5","text":"The eigenvectors maybe have not been sorted in certain edge cases if solver was 'eigen' in PrincipalComponentAnalysis and LinearDiscriminantAnalysis . ( #477 , #478 )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-0140-11-09-2018","text":"","title":"Version 0.14.0 (11-09-2018)"},{"location":"CHANGELOG/#downloads_6","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_6","text":"Added a scatterplotmatrix function to the plotting module. ( #437 ) Added sample_weight option to StackingRegressor , StackingClassifier , StackingCVRegressor , StackingCVClassifier , EnsembleVoteClassifier . ( #438 ) Added a RandomHoldoutSplit class to perform a random train/valid split without rotation in SequentialFeatureSelector , scikit-learn GridSearchCV etc. ( #442 ) Added a PredefinedHoldoutSplit class to perform a train/valid split, based on user-specified indices, without rotation in SequentialFeatureSelector , scikit-learn GridSearchCV etc. ( #443 ) Created a new mlearner.image submodule for working on image processing-related tasks. ( #457 ) Added a new convenience function extract_face_landmarks based on dlib to mlearner.image . ( #458 ) Added a method='oob' option to the mlearner.evaluate.bootstrap_point632_score method to compute the classic out-of-bag bootstrap estimate ( #459 ) Added a method='.632+' option to the mlearner.evaluate.bootstrap_point632_score method to compute the .632+ bootstrap estimate that addresses the optimism bias of the .632 bootstrap ( #459 ) Added a new mlearner.evaluate.ftest function to perform an F-test for comparing the accuracies of two or more classification models. ( #460 ) Added a new mlearner.evaluate.combined_ftest_5x2cv function to perform an combined 5x2cv F-Test for comparing the performance of two models. ( #461 ) Added a new mlearner.evaluate.difference_proportions test for comparing two proportions (e.g., classifier accuracies) ( #462 )","title":"New Features"},{"location":"CHANGELOG/#changes_6","text":"Addressed deprecations warnings in NumPy 0.15. ( #425 ) Because of complications in PR ( #459 ), Python 2.7 was now dropped; since official support for Python 2.7 by the Python Software Foundation is ending in approx. 12 months anyways, this re-focussing will hopefully free up some developer time with regard to not having to worry about backward compatibility","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_6","text":"Fixed an issue with a missing import in mlearner.plotting.plot_confusion_matrix . ( #428 )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-0130-2018-07-20","text":"","title":"Version 0.13.0 (2018-07-20)"},{"location":"CHANGELOG/#downloads_7","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_7","text":"A meaningful error message is now raised when a cross-validation generator is used with SequentialFeatureSelector . ( #377 ) The SequentialFeatureSelector now accepts custom feature names via the fit method for more interpretable feature subset reports. ( #379 ) The SequentialFeatureSelector is now also compatible with Pandas DataFrames and uses DataFrame column-names for more interpretable feature subset reports. ( #379 ) ColumnSelector now works with Pandas DataFrames columns. ( #378 by Manuel Garrido ) The ExhaustiveFeatureSelector estimator in mlearner.feature_selection now is safely stoppable mid-process by control+c. ( #380 ) Two new functions, vectorspace_orthonormalization and vectorspace_dimensionality were added to mlearner.math to use the Gram-Schmidt process to convert a set of linearly independent vectors into a set of orthonormal basis vectors, and to compute the dimensionality of a vectorspace, respectively. ( #382 ) mlearner.frequent_patterns.apriori now supports pandas SparseDataFrame s to generate frequent itemsets. ( #404 via Daniel Morales ) The plot_confusion_matrix function now has the ability to show normalized confusion matrix coefficients in addition to or instead of absolute confusion matrix coefficients with or without a colorbar. The text display method has been changed so that the full range of the colormap is used. The default size is also now set based on the number of classes. Added support for merging the meta features with the original input features in StackingRegressor (via use_features_in_secondary ) like it is already supported in the other Stacking classes. ( #418 ) Added a support_only to the association_rules function, which allow constructing association rules (based on the support metric only) for cropped input DataFrames that don't contain a complete set of antecedent and consequent support values. ( #421 )","title":"New Features"},{"location":"CHANGELOG/#changes_7","text":"Itemsets generated with apriori are now frozenset s ( #393 by William Laney and #394 ) Now raises an error if a input DataFrame to apriori contains non 0, 1, True, False values. #419 )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_7","text":"Allow mlearner estimators to be cloned via scikit-learn's clone function. ( #374 ) Fixes bug to allow the correct use of refit=False in StackingRegressor and StackingCVRegressor ( #384 and ( #385 ) by selay01 ) Allow StackingClassifier to work with sparse matrices when use_features_in_secondary=True ( #408 by Floris Hoogenbook ) Allow StackingCVRegressor to work with sparse matrices when use_features_in_secondary=True ( #416 ) Allow StackingCVClassifier to work with sparse matrices when use_features_in_secondary=True ( #417 )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-0120-2018-21-04","text":"","title":"Version 0.12.0 (2018-21-04)"},{"location":"CHANGELOG/#downloads_8","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_8","text":"A new feature_importance_permuation function to compute the feature importance in classifiers and regressors via the permutation importance method ( #358 ) The fit method of the ExhaustiveFeatureSelector now optionally accepts **fit_params for the estimator that is used for the feature selection. ( #354 by Zach Griffith) The fit method of the SequentialFeatureSelector now optionally accepts **fit_params for the estimator that is used for the feature selection. ( #350 by Zach Griffith)","title":"New Features"},{"location":"CHANGELOG/#changes_8","text":"Replaced plot_decision_regions colors by a colorblind-friendly palette and adds contour lines for decision regions. ( #348 ) All stacking estimators now raise NonFittedErrors if any method for inference is called prior to fitting the estimator. ( #353 ) Renamed the refit parameter of both the StackingClassifier and StackingCVClassifier to use_clones to be more explicit and less misleading. ( #368 )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_8","text":"Various changes in the documentation and documentation tools to fix formatting issues ( #363 ) Fixes a bug where the StackingCVClassifier 's meta features were not stored in the original order when shuffle=True ( #370 ) Many documentation improvements, including links to the User Guides in the API docs ( #371 )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-0110-2018-03-14","text":"","title":"Version 0.11.0 (2018-03-14)"},{"location":"CHANGELOG/#downloads_9","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_9","text":"New function implementing the resampled paired t-test procedure ( paired_ttest_resampled ) to compare the performance of two models. ( #323 ) New function implementing the k-fold paired t-test procedure ( paired_ttest_kfold_cv ) to compare the performance of two models (also called k-hold-out paired t-test). ( #324 ) New function implementing the 5x2cv paired t-test procedure ( paired_ttest_5x2cv ) proposed by Dieterrich (1998) to compare the performance of two models. ( #325 ) A refit parameter was added to stacking classes (similar to the refit parameter in the EnsembleVoteClassifier ), to support classifiers and regressors that follow the scikit-learn API but are not compatible with scikit-learn's clone function. ( #322 ) The ColumnSelector now has a drop_axis argument to use it in pipelines with CountVectorizers . ( #333 )","title":"New Features"},{"location":"CHANGELOG/#changes_9","text":"Raises an informative error message if predict or predict_meta_features is called prior to calling the fit method in StackingRegressor and StackingCVRegressor . ( #315 ) The plot_decision_regions function now automatically determines the optimal setting based on the feature dimensions and supports anti-aliasing. The old res parameter has been deprecated. ( #309 by Guillaume Poirier-Morency ) Apriori code is faster due to optimization in onehot transformation and the amount of candidates generated by the apriori algorithm. ( #327 by Jakub Smid ) The OnehotTransactions class (which is typically often used in combination with the apriori function for association rule mining) is now more memory efficient as it uses boolean arrays instead of integer arrays. In addition, the OnehotTransactions class can be now be provided with sparse argument to generate sparse representations of the onehot matrix to further improve memory efficiency. ( #328 by Jakub Smid ) The OneHotTransactions has been deprecated and replaced by the TransactionEncoder . ( #332 The plot_decision_regions function now has three new parameters, scatter_kwargs , contourf_kwargs , and scatter_highlight_kwargs , that can be used to modify the plotting style. ( #342 by James Bourbeau )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_9","text":"Fixed issue when class labels were provided to the EnsembleVoteClassifier when refit was set to false . ( #322 ) Allow arrays with 16-bit and 32-bit precision in plot_decision_regions function. ( #337 ) Fixed bug that raised an indexing error if the number of items was <= 1 when computing association rules using the conviction metric. ( #340 )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-0100-2017-12-22","text":"","title":"Version 0.10.0 (2017-12-22)"},{"location":"CHANGELOG/#downloads_10","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_10","text":"New store_train_meta_features parameter for fit in StackingCVRegressor. if True, train meta-features are stored in self.train_meta_features_ . New pred_meta_features method for StackingCVRegressor . People can get test meta-features using this method. ( #294 via takashioya ) The new store_train_meta_features attribute and pred_meta_features method for the StackingCVRegressor were also added to the StackingRegressor , StackingClassifier , and StackingCVClassifier ( #299 & #300 ) New function ( evaluate.mcnemar_tables ) for creating multiple 2x2 contigency from model predictions arrays that can be used in multiple McNemar (post-hoc) tests or Cochran's Q or F tests, etc. ( #307 ) New function ( evaluate.cochrans_q ) for performing Cochran's Q test to compare the accuracy of multiple classifiers. ( #310 )","title":"New Features"},{"location":"CHANGELOG/#changes_10","text":"Added requirements.txt to setup.py . ( #304 via Colin Carrol )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_10","text":"Improved numerical stability for p-values computed via the the exact McNemar test ( #306 ) nose is not required to use the library ( #302 )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-091-2017-11-19","text":"","title":"Version 0.9.1 (2017-11-19)"},{"location":"CHANGELOG/#downloads_11","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_11","text":"Added mlearner.evaluate.bootstrap_point632_score to evaluate the performance of estimators using the .632 bootstrap. ( #283 ) New max_len parameter for the frequent itemset generation via the apriori function to allow for early stopping. ( #270 )","title":"New Features"},{"location":"CHANGELOG/#changes_11","text":"All feature index tuples in SequentialFeatureSelector or now in sorted order. ( #262 ) The SequentialFeatureSelector now runs the continuation of the floating inclusion/exclusion as described in Novovicova & Kittler (1994). Note that this didn't cause any difference in performance on any of the test scenarios but could lead to better performance in certain edge cases. ( #262 ) utils.Counter now accepts a name variable to help distinguish between multiple counters, time precision can be set with the 'precision' kwarg and the new attribute end_time holds the time the last iteration completed. ( #278 via Mathew Savage )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_11","text":"Fixed an deprecation error that occured with McNemar test when using SciPy 1.0. ( #283 )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-090-2017-10-21","text":"","title":"Version 0.9.0 (2017-10-21)"},{"location":"CHANGELOG/#downloads_12","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_12","text":"Added evaluate.permutation_test , a permutation test for hypothesis testing (or A/B testing) to test if two samples come from the same distribution. Or in other words, a procedure to test the null hypothesis that that two groups are not significantly different (e.g., a treatment and a control group). ( #250 ) Added 'leverage' and 'conviction as evaluation metrics to the frequent_patterns.association_rules function. ( #246 & #247 ) Added a loadings_ attribute to PrincipalComponentAnalysis to compute the factor loadings of the features on the principal components. ( #251 ) Allow grid search over classifiers/regressors in ensemble and stacking estimators. ( #259 ) New make_multiplexer_dataset function that creates a dataset generated by a n-bit Boolean multiplexer for evaluating supervised learning algorithms. ( #263 ) Added a new BootstrapOutOfBag class, an implementation of the out-of-bag bootstrap to evaluate supervised learning algorithms. ( #265 ) The parameters for StackingClassifier , StackingCVClassifier , StackingRegressor , StackingCVRegressor , and EnsembleVoteClassifier can now be tuned using scikit-learn's GridSearchCV ( #254 via James Bourbeau )","title":"New Features"},{"location":"CHANGELOG/#changes_12","text":"The 'support' column returned by frequent_patterns.association_rules was changed to compute the support of \"antecedant union consequent\", and new antecedant support' and 'consequent support' column were added to avoid ambiguity. ( #245 ) Allow the OnehotTransactions to be cloned via scikit-learn's clone function, which is required by e.g., scikit-learn's FeatureUnion or GridSearchCV (via Iaroslav Shcherbatyi ). ( #249 )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_12","text":"Fix issues with self._init_time parameter in _IterativeModel subclasses. ( #256 ) Fix imprecision bug that occurred in plot_ecdf when run on Python 2.7. ( 264 ) The vectors from SVD in PrincipalComponentAnalysis are now being scaled so that the eigenvalues via solver='eigen' and solver='svd' now store eigenvalues that have the same magnitudes. ( #251 )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-080-2017-09-09","text":"","title":"Version 0.8.0 (2017-09-09)"},{"location":"CHANGELOG/#downloads_13","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_13","text":"Added a mlearner.evaluate.bootstrap that implements the ordinary nonparametric bootstrap to bootstrap a single statistic (for example, the mean. median, R^2 of a regression fit, and so forth) #232 SequentialFeatureSelecor 's k_features now accepts a string argument \"best\" or \"parsimonious\" for more \"automated\" feature selection. For instance, if \"best\" is provided, the feature selector will return the feature subset with the best cross-validation performance. If \"parsimonious\" is provided as an argument, the smallest feature subset that is within one standard error of the cross-validation performance will be selected. #238","title":"New Features"},{"location":"CHANGELOG/#changes_13","text":"SequentialFeatureSelector now uses np.nanmean over normal mean to support scorers that may return np.nan #211 (via mrkaiser ) The skip_if_stuck parameter was removed from SequentialFeatureSelector in favor of a more efficient implementation comparing the conditional inclusion/exclusion results (in the floating versions) to the performances of previously sampled feature sets that were cached #237 ExhaustiveFeatureSelector was modified to consume substantially less memory #195 (via Adam Erickson )","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_13","text":"Fixed a bug where the SequentialFeatureSelector selected a feature subset larger than then specified via the k_features tuple max-value #213","title":"Bug Fixes"},{"location":"CHANGELOG/#version-070-2017-06-22","text":"","title":"Version 0.7.0 (2017-06-22)"},{"location":"CHANGELOG/#downloads_14","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_14","text":"New mlearner.plotting.ecdf function for plotting empirical cumulative distribution functions ( #196 ). New StackingCVRegressor for stacking regressors with out-of-fold predictions to prevent overfitting ( #201 via Eike Dehling ).","title":"New Features"},{"location":"CHANGELOG/#changes_14","text":"The TensorFlow estimator have been removed from mlearner, since TensorFlow has now very convenient ways to build on estimators, which render those implementations obsolete. plot_decision_regions now supports plotting decision regions for more than 2 training features #189 , via James Bourbeau ). Parallel execution in mlearner.feature_selection.SequentialFeatureSelector and mlearner.feature_selection.ExhaustiveFeatureSelector is now performed over different feature subsets instead of the different cross-validation folds to better utilize machines with multiple processors if the number of features is large ( #193 , via @whalebot-helmsman ). Raise meaningful error messages if pandas DataFrame s or Python lists of lists are fed into the StackingCVClassifer as a fit arguments ( 198 ). The n_folds parameter of the StackingCVClassifier was changed to cv and can now accept any kind of cross validation technique that is available from scikit-learn. For example, StackingCVClassifier(..., cv=StratifiedKFold(n_splits=3)) or StackingCVClassifier(..., cv=GroupKFold(n_splits=3)) ( #203 , via Konstantinos Paliouras ).","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_14","text":"SequentialFeatureSelector now correctly accepts a None argument for the scoring parameter to infer the default scoring metric from scikit-learn classifiers and regressors ( #171 ). The plot_decision_regions function now supports pre-existing axes objects generated via matplotlib's plt.subplots . ( #184 , see example ) Made math.num_combinations and math.num_permutations numerically stable for large numbers of combinations and permutations ( #200 ).","title":"Bug Fixes"},{"location":"CHANGELOG/#version-060-2017-03-18","text":"","title":"Version 0.6.0 (2017-03-18)"},{"location":"CHANGELOG/#downloads_15","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_15","text":"An association_rules function is implemented that allows to generate rules based on a list of frequent itemsets (via Joshua Goerner ).","title":"New Features"},{"location":"CHANGELOG/#changes_15","text":"Adds a black edgecolor to plots via plotting.plot_decision_regions to make markers more distinguishable from the background in matplotlib>=2.0 . The association submodule was renamed to frequent_patterns .","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_15","text":"The DataFrame index of apriori results are now unique and ordered. Fixed typos in autompg and wine datasets (via James Bourbeau ).","title":"Bug Fixes"},{"location":"CHANGELOG/#version-051-2017-02-14","text":"","title":"Version 0.5.1 (2017-02-14)"},{"location":"CHANGELOG/#downloads_16","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_16","text":"The EnsembleVoteClassifier has a new refit attribute that prevents refitting classifiers if refit=False to save computational time. Added a new lift_score function in evaluate to compute lift score (via Batuhan Bardak ). StackingClassifier and StackingRegressor support multivariate targets if the underlying models do (via kernc ). StackingClassifier has a new use_features_in_secondary attribute like StackingCVClassifier .","title":"New Features"},{"location":"CHANGELOG/#changes_16","text":"Changed default verbosity level in SequentialFeatureSelector to 0 The EnsembleVoteClassifier now raises a NotFittedError if the estimator wasn't fit before calling predict . (via Anton Loss ) Added new TensorFlow variable initialization syntax to guarantee compatibility with TensorFlow 1.0","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_16","text":"Fixed wrong default value for k_features in SequentialFeatureSelector Cast selected feature subsets in the SequentialFeautureSelector as sets to prevent the iterator from getting stuck if the k_idx are different permutations of the same combination (via Zac Wellmer ). Fixed an issue with learning curves that caused the performance metrics to be reversed (via ipashchenko ) Fixed a bug that could occur in the SequentialFeatureSelector if there are similarly-well performing subsets in the floating variants (via Zac Wellmer ).","title":"Bug Fixes"},{"location":"CHANGELOG/#version-050-2016-11-09","text":"","title":"Version 0.5.0 (2016-11-09)"},{"location":"CHANGELOG/#downloads_17","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_17","text":"New ExhaustiveFeatureSelector estimator in mlearner.feature_selection for evaluating all feature combinations in a specified range The StackingClassifier has a new parameter average_probas that is set to True by default to maintain the current behavior. A deprecation warning was added though, and it will default to False in future releases (0.6.0); average_probas=False will result in stacking of the level-1 predicted probabilities rather than averaging these. New StackingCVClassifier estimator in 'mlearner.classifier' for implementing a stacking ensemble that uses cross-validation techniques for training the meta-estimator to avoid overfitting ( Reiichiro Nakano ) New OnehotTransactions encoder class added to the preprocessing submodule for transforming transaction data into a one-hot encoded array The SequentialFeatureSelector estimator in mlearner.feature_selection now is safely stoppable mid-process by control+c, and deprecated print_progress in favor of a more tunable verbose parameter ( Will McGinnis ) New apriori function in association to extract frequent itemsets from transaction data for association rule mining New checkerboard_plot function in plotting to plot checkerboard tables / heat maps New mcnemar_table and mcnemar functions in evaluate to compute 2x2 contingency tables and McNemar's test","title":"New Features"},{"location":"CHANGELOG/#changes_17","text":"All plotting functions have been moved to mlearner.plotting for compatibility reasons with continuous integration services and to make the installation of matplotlib optional for users of mlearner 's core functionality Added a compatibility layer for scikit-learn 0.18 using the new model_selection module while maintaining backwards compatibility to scikit-learn 0.17.","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_17","text":"mlearner.plotting.plot_decision_regions now draws decision regions correctly if more than 4 class labels are present Raise AttributeError in plot_decision_regions when the X_higlight argument is a 1D array ( chkoar )","title":"Bug Fixes"},{"location":"CHANGELOG/#version-042-2016-08-24","text":"","title":"Version 0.4.2 (2016-08-24)"},{"location":"CHANGELOG/#downloads_18","text":"Source code (zip) Source code (tar.gz) PDF documentation","title":"Downloads"},{"location":"CHANGELOG/#new-features_18","text":"Added preprocessing.CopyTransformer , a mock class that returns copies of imput arrays via transform and fit_transform","title":"New Features"},{"location":"CHANGELOG/#changes_18","text":"Added AppVeyor to CI to ensure MS Windows compatibility Dataset are now saved as compressed .txt or .csv files rather than being imported as Python objects feature_selection.SequentialFeatureSelector now supports the selection of k_features using a tuple to specify a \"min-max\" k_features range Added \"SVD solver\" option to the PrincipalComponentAnalysis Raise a AttributeError with \"not fitted\" message in SequentialFeatureSelector if transform or get_metric_dict are called prior to fit Use small, positive bias units in TfMultiLayerPerceptron 's hidden layer(s) if the activations are ReLUs in order to avoid dead neurons Added an optional clone_estimator parameter to the SequentialFeatureSelector that defaults to True , avoiding the modification of the original estimator objects More rigorous type and shape checks in the evaluate.plot_decision_regions function DenseTransformer now doesn't raise and error if the input array is not sparse API clean-up using scikit-learn's BaseEstimator as parent class for feature_selection.ColumnSelector","title":"Changes"},{"location":"CHANGELOG/#bug-fixes_18","text":"Fixed a problem when a tuple-range was provided as argument to the SequentialFeatureSelector 's k_features parameter and the scoring metric was more negative than -1 (e.g., as in scikit-learn's MSE scoring function) (wahutch](https://github.com/wahutch)) Fixed an AttributeError issue when verbose > 1 in StackingClassifier Fixed a bug in classifier.SoftmaxRegression where the mean values of the offsets were used to update the bias units rather than their sum Fixed rare bug in MLP _layer_mapping functions that caused a swap between the random number generation seed when initializing weights and biases","title":"Bug Fixes"},{"location":"CHANGELOG/#version-041-2016-05-01","text":"","title":"Version 0.4.1 (2016-05-01)"},{"location":"CHANGELOG/#downloads_19","text":"Source code (zip) Source code (tar.gz) PDF documentation","title":"Downloads"},{"location":"CHANGELOG/#new-features_19","text":"New TensorFlow estimator for Linear Regression ( tf_regressor.TfLinearRegression ) New k-means clustering estimator ( cluster.Kmeans ) New TensorFlow k-means clustering estimator ( tf_cluster.Kmeans )","title":"New Features"},{"location":"CHANGELOG/#changes_19","text":"Due to refactoring of the estimator classes, the init_weights parameter of the fit methods was globally renamed to init_params Overall performance improvements of estimators due to code clean-up and refactoring Added several additional checks for correct array types and more meaningful exception messages Added optional dropout to the tf_classifier.TfMultiLayerPerceptron classifier for regularization Added an optional decay parameter to the tf_classifier.TfMultiLayerPerceptron classifier for adaptive learning via an exponential decay of the learning rate eta Replaced old NeuralNetMLP by more streamlined MultiLayerPerceptron ( classifier.MultiLayerPerceptron ); now also with softmax in the output layer and categorical cross-entropy loss. Unified init_params parameter for fit functions to continue training where the algorithm left off (if supported)","title":"Changes"},{"location":"CHANGELOG/#version-040-2016-04-09","text":"","title":"Version 0.4.0 (2016-04-09)"},{"location":"CHANGELOG/#new-features_20","text":"New TfSoftmaxRegression classifier using Tensorflow ( tf_classifier.TfSoftmaxRegression ) New SoftmaxRegression classifier ( classifier.SoftmaxRegression ) New TfMultiLayerPerceptron classifier using Tensorflow ( tf_classifier.TfMultiLayerPerceptron ) New StackingRegressor ( regressor.StackingRegressor ) New StackingClassifier ( classifier.StackingClassifier ) New function for one-hot encoding of class labels ( preprocessing.one_hot ) Added GridSearch support to the SequentialFeatureSelector ( feature_selection/.SequentialFeatureSelector ) evaluate.plot_decision_regions improvements: Function now handles class y-class labels correctly if array is of type float Correct handling of input arguments markers and colors Accept an existing Axes via the ax argument New print_progress parameter for all generalized models and multi-layer neural networks for printing time elapsed, ETA, and the current cost of the current epoch Minibatch learning for classifier.LogisticRegression , classifier.Adaline , and regressor.LinearRegression plus streamlined API New Principal Component Analysis class via mlearner.feature_extraction.PrincipalComponentAnalysis New RBF Kernel Principal Component Analysis class via mlearner.feature_extraction.RBFKernelPCA New Linear Discriminant Analysis class via mlearner.feature_extraction.LinearDiscriminantAnalysis","title":"New Features"},{"location":"CHANGELOG/#changes_20","text":"The column parameter in mlearner.preprocessing.standardize now defaults to None to standardize all columns more conveniently","title":"Changes"},{"location":"CHANGELOG/#version-030-2016-01-31","text":"","title":"Version 0.3.0 (2016-01-31)"},{"location":"CHANGELOG/#downloads_20","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_21","text":"Added a progress bar tracker to classifier.NeuralNetMLP Added a function to score predicted vs. target class labels evaluate.scoring Added confusion matrix functions to create ( evaluate.confusion_matrix ) and plot ( evaluate.plot_confusion_matrix ) confusion matrices New style parameter and improved axis scaling in mlearner.evaluate.plot_learning_curves Added loadlocal_mnist to mlearner.data for streaming MNIST from a local byte files into numpy arrays New NeuralNetMLP parameters: random_weights , shuffle_init , shuffle_epoch New SFS features such as the generation of pandas DataFrame results tables and plotting functions (with confidence intervals, standard deviation, and standard error bars) Added support for regression estimators in SFS Added Boston housing dataset New shuffle parameter for classifier.NeuralNetMLP","title":"New Features"},{"location":"CHANGELOG/#changes_21","text":"The mlearner.preprocessing.standardize function now optionally returns the parameters, which are estimated from the array, for re-use. A further improvement makes the standardize function smarter in order to avoid zero-division errors Cosmetic improvements to the evaluate.plot_decision_regions function such as hiding plot axes Renaming of classifier.EnsembleClassfier to classifier.EnsembleVoteClassifier Improved random weight initialization in Perceptron , Adaline , LinearRegression , and LogisticRegression Changed learning parameter of mlearner.classifier.Adaline to solver and added \"normal equation\" as closed-form solution solver Hide y-axis labels in mlearner.evaluate.plot_decision_regions in 1 dimensional evaluations Sequential Feature Selection algorithms were unified into a single SequentialFeatureSelector class with parameters to enable floating selection and toggle between forward and backward selection. Stratified sampling of MNIST (now 500x random samples from each of the 10 digit categories) Renaming mlearner.plotting to mlearner.general_plotting in order to distinguish general plotting function from specialized utility function such as evaluate.plot_decision_regions","title":"Changes"},{"location":"CHANGELOG/#version-029-2015-07-14","text":"","title":"Version 0.2.9 (2015-07-14)"},{"location":"CHANGELOG/#downloads_21","text":"Source code (zip) Source code (tar.gz)","title":"Downloads"},{"location":"CHANGELOG/#new-features_22","text":"Sequential Feature Selection algorithms: SFS, SFFS, SBS, and SFBS","title":"New Features"},{"location":"CHANGELOG/#changes_22","text":"Changed regularization & lambda parameters in LogisticRegression to single parameter l2_lambda","title":"Changes"},{"location":"CHANGELOG/#version-028-2015-06-27","text":"API changes: mlearner.sklearn.EnsembleClassifier -> mlearner.classifier.EnsembleClassifier mlearner.sklearn.ColumnSelector -> mlearner.feature_selection.ColumnSelector mlearner.sklearn.DenseTransformer -> mlearner.preprocessing.DenseTransformer mlearner.pandas.standardizing -> mlearner.preprocessing.standardizing mlearner.pandas.minmax_scaling -> mlearner.preprocessing.minmax_scaling mlearner.matplotlib -> mlearner.plotting Added momentum learning parameter (alpha coefficient) to mlearner.classifier.NeuralNetMLP . Added adaptive learning rate (decrease constant) to mlearner.classifier.NeuralNetMLP . mlearner.pandas.minmax_scaling became mlearner.preprocessing.minmax_scaling and also supports NumPy arrays now mlearner.pandas.standardizing became mlearner.preprocessing.standardizing and now supports both NumPy arrays and pandas DataFrames; also, now ddof parameters to set the degrees of freedom when calculating the standard deviation","title":"Version 0.2.8 (2015-06-27)"},{"location":"CHANGELOG/#version-027-2015-06-20","text":"Added multilayer perceptron (feedforward artificial neural network) classifier as mlearner.classifier.NeuralNetMLP . Added 5000 labeled trainingsamples from the MNIST handwritten digits dataset to mlearner.data","title":"Version 0.2.7 (2015-06-20)"},{"location":"CHANGELOG/#version-026-2015-05-08","text":"Added ordinary least square regression using different solvers (gradient and stochastic gradient descent, and the closed form solution (normal equation) Added option for random weight initialization to logistic regression classifier and updated l2 regularization Added wine dataset to mlearner.data Added invert_axes parameter mlearner.matplotlib.enrichtment_plot to optionally plot the \"Count\" on the x-axis New verbose parameter for mlearner.sklearn.EnsembleClassifier by Alejandro C. Bahnsen Added mlearner.pandas.standardizing to standardize columns in a Pandas DataFrame Added parameters linestyles and markers to mlearner.matplotlib.enrichment_plot mlearner.regression.lin_regplot automatically adds np.newaxis and works w. python lists Added tokenizers: mlearner.text.extract_emoticons and mlearner.text.extract_words_and_emoticons","title":"Version 0.2.6 (2015-05-08)"},{"location":"CHANGELOG/#version-025-2015-04-17","text":"Added Sequential Backward Selection (mlearner.sklearn.SBS) Added X_highlight parameter to mlearner.evaluate.plot_decision_regions for highlighting test data points. Added mlearner.regression.lin_regplot to plot the fitted line from linear regression. Added mlearner.matplotlib.stacked_barplot to conveniently produce stacked barplots using pandas DataFrame s. Added mlearner.matplotlib.enrichment_plot","title":"Version 0.2.5 (2015-04-17)"},{"location":"CHANGELOG/#version-024-2015-03-15","text":"Added scoring to mlearner.evaluate.learning_curves (by user pfsq) Fixed setup.py bug caused by the missing README.html file matplotlib.category_scatter for pandas DataFrames and Numpy arrays","title":"Version 0.2.4 (2015-03-15)"},{"location":"CHANGELOG/#version-023-2015-03-11","text":"Added Logistic regression Gradient descent and stochastic gradient descent perceptron was changed to Adaline (Adaptive Linear Neuron) Perceptron and Adaline for {0, 1} classes Added mlearner.preprocessing.shuffle_arrays_unison function to shuffle one or more NumPy arrays. Added shuffle and random seed parameter to stochastic gradient descent classifier. Added rstrip parameter to mlearner.file_io.find_filegroups to allow trimming of base names. Added ignore_substring parameter to mlearner.file_io.find_filegroups and find_files . Replaced .rstrip in mlearner.file_io.find_filegroups with more robust regex. Gridsearch support for mlearner.sklearn.EnsembleClassifier","title":"Version 0.2.3 (2015-03-11)"},{"location":"CHANGELOG/#version-022-2015-03-01","text":"Improved robustness of EnsembleClassifier. Extended plot_decision_regions() functionality for plotting 1D decision boundaries. Function matplotlib.plot_decision_regions was reorganized to evaluate.plot_decision_regions . evaluate.plot_learning_curves() function added. Added Rosenblatt, gradient descent, and stochastic gradient descent perceptrons.","title":"Version 0.2.2 (2015-03-01)"},{"location":"CHANGELOG/#version-021-2015-01-20","text":"Added mlearner.pandas.minmax_scaling - a function to rescale pandas DataFrame columns. Slight update to the EnsembleClassifier interface (additional voting parameter) Fixed EnsembleClassifier to return correct class labels if class labels are not integers from 0 to n. Added new matplotlib function to plot decision regions of classifiers.","title":"Version 0.2.1 (2015-01-20)"},{"location":"CHANGELOG/#version-020-2015-01-13","text":"Improved mlearner.text.generalize_duplcheck to remove duplicates and prevent endless looping issue. Added recursive search parameter to mlearner.file_io.find_files. Added check_ext parameter mlearner.file_io.find_files to search based on file extensions. Default parameter to ignore invisible files for mlearner.file_io.find. Added transform and fit_transform to the EnsembleClassifier . Added mlearner.file_io.find_filegroups function.","title":"Version 0.2.0 (2015-01-13)"},{"location":"CHANGELOG/#version-019-2015-01-10","text":"Implemented scikit-learn EnsembleClassifier (majority voting rule) class.","title":"Version 0.1.9 (2015-01-10)"},{"location":"CHANGELOG/#version-018-2015-01-07","text":"Improvements to mlearner.text.generalize_names to handle certain Dutch last name prefixes (van, van der, de, etc.). Added mlearner.text.generalize_name_duplcheck function to apply mlearner.text.generalize_names function to a pandas DataFrame without creating duplicates.","title":"Version 0.1.8 (2015-01-07)"},{"location":"CHANGELOG/#version-017-2015-01-07","text":"Added text utilities with name generalization function. Added and file_io utilities.","title":"Version 0.1.7 (2015-01-07)"},{"location":"CHANGELOG/#version-016-2015-01-04","text":"Added combinations and permutations estimators.","title":"Version 0.1.6 (2015-01-04)"},{"location":"CHANGELOG/#version-015-2014-12-11","text":"Added DenseTransformer for pipelines and grid search.","title":"Version 0.1.5 (2014-12-11)"},{"location":"CHANGELOG/#version-014-2014-08-20","text":"mean_centering function is now a Class that creates MeanCenterer objects that can be used to fit data via the fit method, and center data at the column means via the transform and fit_transform method.","title":"Version 0.1.4 (2014-08-20)"},{"location":"CHANGELOG/#version-013-2014-08-19","text":"Added preprocessing module and mean_centering function.","title":"Version 0.1.3 (2014-08-19)"},{"location":"CHANGELOG/#version-012-2014-08-19","text":"Added matplotlib utilities and remove_borders function.","title":"Version 0.1.2 (2014-08-19)"},{"location":"CHANGELOG/#version-011-2014-08-13","text":"Simplified code for ColumnSelector.","title":"Version 0.1.1 (2014-08-13)"},{"location":"CONTRIBUTING/","text":"How to Contribute I would be very happy about any kind of contributions that help to improve and extend the functionality of mlearner. Quick Contributor Checklist This is a quick checklist about the different steps of a typical contribution to mlearner (and other open source projects). Consider copying this list to a local text file (or the issue tracker) and checking off items as you go. [ ] Open a new \"issue\" on GitHub to discuss the new feature / bug fix [ ] Fork the mlearner repository from GitHub (if not already done earlier) [ ] Create and check out a new topic branch (please don't make modifications in the master branch) [ ] Implement the new feature or apply the bug-fix [ ] Add appropriate unit test functions in mlearner/*/tests [ ] Run PYTHONPATH='.' pytest ./mlearner -sv and make sure that all unit tests pass [ ] Check for style issues by running flake8 ./mlearner (you may want to run pytest again after you made modifications to the code) [ ] Add a note about the modification/contribution to the ./docs/sources/changelog.md file [ ] Modify documentation in the appropriate location under mlearner/docs/sources/ [ ] Push the topic branch to the server and create a pull request [ ] Check the Travis-CI build passed at https://travis-ci.org/rasbt/mlearner [ ] Check/improve the unit test coverage at https://coveralls.io/github/rasbt/mlearner [ ] Check/improve the code health at https://landscape.io/github/rasbt/mlearner Tips for Contributors Getting Started - Creating a New Issue and Forking the Repository If you don't have a GitHub account, yet, please create one to contribute to this project. Please submit a ticket for your issue to discuss the fix or new feature before too much time and effort is spent for the implementation. Fork the mlearner repository from the GitHub web interface. Clone the mlearner repository to your local machine by executing git clone https://github.com/<your_username>/mlearner.git Syncing an Existing Fork If you already forked mlearner earlier, you can bring you \"Fork\" up to date with the master branch as follows: 1. Configuring a remote that points to the upstream repository on GitHub List the current configured remote repository of your fork by executing $ git remote -v If you see something like origin https://github.com/<your username>/mlearner.git (fetch) origin https://github.com/<your username>/mlearner.git (push) you need to specify a new remote upstream repository via $ git remote add upstream https://github.com/jaisenbe58r/MLearner.git Now, verify the new upstream repository you've specified for your fork by executing $ git remote -v You should see following output if everything is configured correctly: origin https://github.com/<your username>/mlearner.git (fetch) origin https://github.com/<your username>/mlearner.git (push) upstream https://github.com/jaisenbe58r/MLearner.git (fetch) upstream https://github.com/jaisenbe58r/MLearner.git (push) 2. Syncing your Fork First, fetch the updates of the original project's master branch by executing: $ git fetch upstream You should see the following output remote: Counting objects: xx, done. remote: Compressing objects: 100% (xx/xx), done. remote: Total xx (delta xx), reused xx (delta x) Unpacking objects: 100% (xx/xx), done. From https://github.com/jaisenbe58r/MLearner * [new branch] master -> upstream/master This means that the commits to the rasbt/mlearner master branch are now stored in the local branch upstream/master . If you are not already on your local project's master branch, execute $ git checkout master Finally, merge the changes in upstream/master to your local master branch by executing $ git merge upstream/master which will give you an output that looks similar to Updating xxx...xxx Fast-forward SOME FILE1 | 12 +++++++ SOME FILE2 | 10 +++++++ 2 files changed, 22 insertions(+), *The Main Workflow - Making Changes in a New Topic Branch Listed below are the 9 typical steps of a contribution. 1. Discussing the Feature or Modification Before you start coding, please discuss the new feature, bugfix, or other modification to the project on the project's issue tracker . Before you open a \"new issue,\" please do a quick search to see if a similar issue has been submitted already. 2. Creating a new feature branch Please avoid working directly on the master branch but create a new feature branch: $ git branch <new_feature> Switch to the new feature branch by executing $ git checkout <new_feature> 3. Developing the new feature / bug fix Now it's time to modify existing code or to contribute new code to the project. 4. Testing your code Add the respective unit tests and check if they pass: $ PYTHONPATH='.' pytest ./mlearner ---with-coverage 5. Documenting changes Please add an entry to the mlearner/docs/sources/changelog.md file. If it is a new feature, it would also be nice if you could update the documentation in appropriate location in mlearner/sources . 6. Committing changes When you are ready to commit the changes, please provide a meaningful commit message: $ git add <modifies_files> # or `git add .` $ git commit -m '<meaningful commit message>' 7. Optional: squashing commits If you made multiple smaller commits, it would be nice if you could group them into a larger, summarizing commit. First, list your recent commit via Note Due to the improved GitHub UI, this is no longer necessary/encouraged. $ git log which will list the commits from newest to oldest in the following format by default: commit 046e3af8a9127df8eac879454f029937c8a31c41 Author: rasbt <mail@sebastianraschka.com> Date: Tue Nov 24 03:46:37 2015 -0500 fixed setup.py commit c3c00f6ba0e8f48bbe1c9081b8ae3817e57ecc5c Author: rasbt <mail@sebastianraschka.com> Date: Tue Nov 24 03:04:39 2015 -0500 documented feature x commit d87934fe8726c46f0b166d6290a3bf38915d6e75 Author: rasbt <mail@sebastianraschka.com> Date: Tue Nov 24 02:44:45 2015 -0500 added support for feature x Assuming that it would make sense to group these 3 commits into one, we can execute $ git rebase -i HEAD~3 which will bring our default git editor with the following contents: pick d87934f added support for feature x pick c3c00f6 documented feature x pick 046e3af fixed setup.py Since c3c00f6 and 046e3af are related to the original commit of feature x , let's keep the d87934f and squash the 2 following commits into this initial one by changes the lines to pick d87934f added support for feature x squash c3c00f6 documented feature x squash 046e3af fixed setup.py Now, save the changes in your editor. Now, quitting the editor will apply the rebase changes, and the editor will open a second time, prompting you to enter a new commit message. In this case, we could enter support for feature x to summarize the contributions. 8. Uploading changes Push your changes to a topic branch to the git server by executing: $ git push origin <feature_branch> 9. Submitting a pull request Go to your GitHub repository online, select the new feature branch, and submit a new pull request: Notes for Developers Building the documentation The documentation is built via MkDocs ; to ensure that the documentation is rendered correctly, you can view the documentation locally by executing mkdocs serve from the mlearner/docs directory. For example, ~/github/mlearner/docs$ mkdocs serve 1. Building the API documentation To build the API documentation, navigate to mlearner/docs and execute the make_api.py file from this directory via ~/github/mlearner/docs$ python make_api.py This should place the API documentation into the correct directories into the two directories: mlearner/docs/sources/api_modules mlearner/docs/sources/api_subpackes 2. Editing the User Guide The documents containing code examples for the \"User Guide\" are generated from IPython Notebook files. In order to convert a IPython notebook file to markdown after editing, please follow the following steps: Modify or edit the existing notebook. Execute all cells in the current notebook and make sure that no errors occur. Convert the notebook to markdown using the ipynb2markdown.py converter ~/github/mlearner/docs$ python ipynb2markdown.py --ipynb_path ./sources/user_guide/subpackage/notebookname.ipynb Note If you are adding a new document, please also include it in the pages section in the mlearner/docs/mkdocs.yml file. 3. Building static HTML files of the documentation First, please check the documenation via localhost (http://127.0.0.1:8000/): ~/github/mlearner/docs$ mkdocs serve Next, build the static HTML files of the mlearner documentation via ~/github/mlearner/docs$ mkdocs build --clean To deploy the documentation, execute ~/github/mlearner/docs$ mkdocs gh-deploy --clean 4. Generate a PDF of the documentation To generate a PDF version of the documentation, simply cd into the mlearner/docs directory and execute: python md2pdf.py Uploading a new version to PyPI 1. Creating a new testing environment Assuming we are using conda , create a new python environment via $ conda create -n 'mlearner-testing' python=3 numpy scipy pandas Next, activate the environment by executing $ source activate mlearner-testing 2. Installing the package from local files Test the installation by executing $ python setup.py install --record files.txt the --record files.txt flag will create a files.txt file listing the locations where these files will be installed. Try to import the package to see if it works, for example, by executing $ python -c 'import mlearner; print(mlearner.__file__)' If everything seems to be fine, remove the installation via $ cat files.txt | xargs rm -rf ; rm files.txt Next, test if pip is able to install the packages. First, navigate to a different directory, and from there, install the package: $ pip install mlearner and uninstall it again $ pip uninstall mlearner 3. Deploying the package Consider deploying the package to the PyPI test server first. The setup instructions can be found here . $ python setup.py sdist bdist_wheel upload -r https://testpypi.python.org/pypi Test if it can be installed from there by executing $ pip install -i https://testpypi.python.org/pypi mlearner and uninstall it $ pip uninstall mlearner After this dry-run succeeded, repeat this process using the \"real\" PyPI: $ python setup.py sdist bdist_wheel upload 4. Removing the virtual environment Finally, to cleanup our local drive, remove the virtual testing environment via $ conda remove --name 'mlearner-testing' --all 5. Updating the conda-forge recipe Once a new version of mlearner has been uploaded to PyPI, update the conda-forge build recipe at https://github.com/conda-forge/mlearner-feedstock by changing the version number in the recipe/meta.yaml file appropriately.","title":"How To Contribute"},{"location":"CONTRIBUTING/#how-to-contribute","text":"I would be very happy about any kind of contributions that help to improve and extend the functionality of mlearner.","title":"How to Contribute"},{"location":"CONTRIBUTING/#quick-contributor-checklist","text":"This is a quick checklist about the different steps of a typical contribution to mlearner (and other open source projects). Consider copying this list to a local text file (or the issue tracker) and checking off items as you go. [ ] Open a new \"issue\" on GitHub to discuss the new feature / bug fix [ ] Fork the mlearner repository from GitHub (if not already done earlier) [ ] Create and check out a new topic branch (please don't make modifications in the master branch) [ ] Implement the new feature or apply the bug-fix [ ] Add appropriate unit test functions in mlearner/*/tests [ ] Run PYTHONPATH='.' pytest ./mlearner -sv and make sure that all unit tests pass [ ] Check for style issues by running flake8 ./mlearner (you may want to run pytest again after you made modifications to the code) [ ] Add a note about the modification/contribution to the ./docs/sources/changelog.md file [ ] Modify documentation in the appropriate location under mlearner/docs/sources/ [ ] Push the topic branch to the server and create a pull request [ ] Check the Travis-CI build passed at https://travis-ci.org/rasbt/mlearner [ ] Check/improve the unit test coverage at https://coveralls.io/github/rasbt/mlearner [ ] Check/improve the code health at https://landscape.io/github/rasbt/mlearner","title":"Quick Contributor Checklist"},{"location":"CONTRIBUTING/#tips-for-contributors","text":"","title":"Tips for Contributors"},{"location":"CONTRIBUTING/#getting-started-creating-a-new-issue-and-forking-the-repository","text":"If you don't have a GitHub account, yet, please create one to contribute to this project. Please submit a ticket for your issue to discuss the fix or new feature before too much time and effort is spent for the implementation. Fork the mlearner repository from the GitHub web interface. Clone the mlearner repository to your local machine by executing git clone https://github.com/<your_username>/mlearner.git","title":"Getting Started - Creating a New Issue and Forking the Repository"},{"location":"CONTRIBUTING/#syncing-an-existing-fork","text":"If you already forked mlearner earlier, you can bring you \"Fork\" up to date with the master branch as follows:","title":"Syncing an Existing Fork"},{"location":"CONTRIBUTING/#1-configuring-a-remote-that-points-to-the-upstream-repository-on-github","text":"List the current configured remote repository of your fork by executing $ git remote -v If you see something like origin https://github.com/<your username>/mlearner.git (fetch) origin https://github.com/<your username>/mlearner.git (push) you need to specify a new remote upstream repository via $ git remote add upstream https://github.com/jaisenbe58r/MLearner.git Now, verify the new upstream repository you've specified for your fork by executing $ git remote -v You should see following output if everything is configured correctly: origin https://github.com/<your username>/mlearner.git (fetch) origin https://github.com/<your username>/mlearner.git (push) upstream https://github.com/jaisenbe58r/MLearner.git (fetch) upstream https://github.com/jaisenbe58r/MLearner.git (push)","title":"1. Configuring a remote that points to the upstream repository on GitHub"},{"location":"CONTRIBUTING/#2-syncing-your-fork","text":"First, fetch the updates of the original project's master branch by executing: $ git fetch upstream You should see the following output remote: Counting objects: xx, done. remote: Compressing objects: 100% (xx/xx), done. remote: Total xx (delta xx), reused xx (delta x) Unpacking objects: 100% (xx/xx), done. From https://github.com/jaisenbe58r/MLearner * [new branch] master -> upstream/master This means that the commits to the rasbt/mlearner master branch are now stored in the local branch upstream/master . If you are not already on your local project's master branch, execute $ git checkout master Finally, merge the changes in upstream/master to your local master branch by executing $ git merge upstream/master which will give you an output that looks similar to Updating xxx...xxx Fast-forward SOME FILE1 | 12 +++++++ SOME FILE2 | 10 +++++++ 2 files changed, 22 insertions(+),","title":"2. Syncing your Fork"},{"location":"CONTRIBUTING/#the-main-workflow-making-changes-in-a-new-topic-branch","text":"Listed below are the 9 typical steps of a contribution.","title":"*The Main Workflow - Making Changes in a New Topic Branch"},{"location":"CONTRIBUTING/#1-discussing-the-feature-or-modification","text":"Before you start coding, please discuss the new feature, bugfix, or other modification to the project on the project's issue tracker . Before you open a \"new issue,\" please do a quick search to see if a similar issue has been submitted already.","title":"1. Discussing the Feature or Modification"},{"location":"CONTRIBUTING/#2-creating-a-new-feature-branch","text":"Please avoid working directly on the master branch but create a new feature branch: $ git branch <new_feature> Switch to the new feature branch by executing $ git checkout <new_feature>","title":"2. Creating a new feature branch"},{"location":"CONTRIBUTING/#3-developing-the-new-feature-bug-fix","text":"Now it's time to modify existing code or to contribute new code to the project.","title":"3. Developing the new feature / bug fix"},{"location":"CONTRIBUTING/#4-testing-your-code","text":"Add the respective unit tests and check if they pass: $ PYTHONPATH='.' pytest ./mlearner ---with-coverage","title":"4. Testing your code"},{"location":"CONTRIBUTING/#5-documenting-changes","text":"Please add an entry to the mlearner/docs/sources/changelog.md file. If it is a new feature, it would also be nice if you could update the documentation in appropriate location in mlearner/sources .","title":"5. Documenting changes"},{"location":"CONTRIBUTING/#6-committing-changes","text":"When you are ready to commit the changes, please provide a meaningful commit message: $ git add <modifies_files> # or `git add .` $ git commit -m '<meaningful commit message>'","title":"6. Committing changes"},{"location":"CONTRIBUTING/#7-optional-squashing-commits","text":"If you made multiple smaller commits, it would be nice if you could group them into a larger, summarizing commit. First, list your recent commit via Note Due to the improved GitHub UI, this is no longer necessary/encouraged. $ git log which will list the commits from newest to oldest in the following format by default: commit 046e3af8a9127df8eac879454f029937c8a31c41 Author: rasbt <mail@sebastianraschka.com> Date: Tue Nov 24 03:46:37 2015 -0500 fixed setup.py commit c3c00f6ba0e8f48bbe1c9081b8ae3817e57ecc5c Author: rasbt <mail@sebastianraschka.com> Date: Tue Nov 24 03:04:39 2015 -0500 documented feature x commit d87934fe8726c46f0b166d6290a3bf38915d6e75 Author: rasbt <mail@sebastianraschka.com> Date: Tue Nov 24 02:44:45 2015 -0500 added support for feature x Assuming that it would make sense to group these 3 commits into one, we can execute $ git rebase -i HEAD~3 which will bring our default git editor with the following contents: pick d87934f added support for feature x pick c3c00f6 documented feature x pick 046e3af fixed setup.py Since c3c00f6 and 046e3af are related to the original commit of feature x , let's keep the d87934f and squash the 2 following commits into this initial one by changes the lines to pick d87934f added support for feature x squash c3c00f6 documented feature x squash 046e3af fixed setup.py Now, save the changes in your editor. Now, quitting the editor will apply the rebase changes, and the editor will open a second time, prompting you to enter a new commit message. In this case, we could enter support for feature x to summarize the contributions.","title":"7. Optional: squashing commits"},{"location":"CONTRIBUTING/#8-uploading-changes","text":"Push your changes to a topic branch to the git server by executing: $ git push origin <feature_branch>","title":"8. Uploading changes"},{"location":"CONTRIBUTING/#9-submitting-a-pull-request","text":"Go to your GitHub repository online, select the new feature branch, and submit a new pull request:","title":"9. Submitting a pull request"},{"location":"CONTRIBUTING/#notes-for-developers","text":"","title":"Notes for Developers"},{"location":"CONTRIBUTING/#building-the-documentation","text":"The documentation is built via MkDocs ; to ensure that the documentation is rendered correctly, you can view the documentation locally by executing mkdocs serve from the mlearner/docs directory. For example, ~/github/mlearner/docs$ mkdocs serve","title":"Building the documentation"},{"location":"CONTRIBUTING/#1-building-the-api-documentation","text":"To build the API documentation, navigate to mlearner/docs and execute the make_api.py file from this directory via ~/github/mlearner/docs$ python make_api.py This should place the API documentation into the correct directories into the two directories: mlearner/docs/sources/api_modules mlearner/docs/sources/api_subpackes","title":"1. Building the API documentation"},{"location":"CONTRIBUTING/#2-editing-the-user-guide","text":"The documents containing code examples for the \"User Guide\" are generated from IPython Notebook files. In order to convert a IPython notebook file to markdown after editing, please follow the following steps: Modify or edit the existing notebook. Execute all cells in the current notebook and make sure that no errors occur. Convert the notebook to markdown using the ipynb2markdown.py converter ~/github/mlearner/docs$ python ipynb2markdown.py --ipynb_path ./sources/user_guide/subpackage/notebookname.ipynb Note If you are adding a new document, please also include it in the pages section in the mlearner/docs/mkdocs.yml file.","title":"2. Editing the User Guide"},{"location":"CONTRIBUTING/#3-building-static-html-files-of-the-documentation","text":"First, please check the documenation via localhost (http://127.0.0.1:8000/): ~/github/mlearner/docs$ mkdocs serve Next, build the static HTML files of the mlearner documentation via ~/github/mlearner/docs$ mkdocs build --clean To deploy the documentation, execute ~/github/mlearner/docs$ mkdocs gh-deploy --clean","title":"3. Building static HTML files of the documentation"},{"location":"CONTRIBUTING/#4-generate-a-pdf-of-the-documentation","text":"To generate a PDF version of the documentation, simply cd into the mlearner/docs directory and execute: python md2pdf.py","title":"4. Generate a PDF of the documentation"},{"location":"CONTRIBUTING/#uploading-a-new-version-to-pypi","text":"","title":"Uploading a new version to PyPI"},{"location":"CONTRIBUTING/#1-creating-a-new-testing-environment","text":"Assuming we are using conda , create a new python environment via $ conda create -n 'mlearner-testing' python=3 numpy scipy pandas Next, activate the environment by executing $ source activate mlearner-testing","title":"1. Creating a new testing environment"},{"location":"CONTRIBUTING/#2-installing-the-package-from-local-files","text":"Test the installation by executing $ python setup.py install --record files.txt the --record files.txt flag will create a files.txt file listing the locations where these files will be installed. Try to import the package to see if it works, for example, by executing $ python -c 'import mlearner; print(mlearner.__file__)' If everything seems to be fine, remove the installation via $ cat files.txt | xargs rm -rf ; rm files.txt Next, test if pip is able to install the packages. First, navigate to a different directory, and from there, install the package: $ pip install mlearner and uninstall it again $ pip uninstall mlearner","title":"2. Installing the package from local files"},{"location":"CONTRIBUTING/#3-deploying-the-package","text":"Consider deploying the package to the PyPI test server first. The setup instructions can be found here . $ python setup.py sdist bdist_wheel upload -r https://testpypi.python.org/pypi Test if it can be installed from there by executing $ pip install -i https://testpypi.python.org/pypi mlearner and uninstall it $ pip uninstall mlearner After this dry-run succeeded, repeat this process using the \"real\" PyPI: $ python setup.py sdist bdist_wheel upload","title":"3. Deploying the package"},{"location":"CONTRIBUTING/#4-removing-the-virtual-environment","text":"Finally, to cleanup our local drive, remove the virtual testing environment via $ conda remove --name 'mlearner-testing' --all","title":"4. Removing the virtual environment"},{"location":"CONTRIBUTING/#5-updating-the-conda-forge-recipe","text":"Once a new version of mlearner has been uploaded to PyPI, update the conda-forge build recipe at https://github.com/conda-forge/mlearner-feedstock by changing the version number in the recipe/meta.yaml file appropriately.","title":"5. Updating the conda-forge recipe"},{"location":"USER_GUIDE_INDEX/","text":"User Guide Index classifier Adaline EnsembleVoteClassifier LogisticRegression MultiLayerPerceptron Perceptron SoftmaxRegression StackingClassifier StackingCVClassifier cluster Kmeans data autompg_data boston_housing_data iris_data loadlocal_mnist make_multiplexer_dataset mnist_data three_blobs_data wine_data evaluate accuracy_score bias_variance_decomp bootstrap bootstrap_point632_score BootstrapOutOfBag cochrans_q confusion_matrix combined_ftest_5x2cv feature_importance_permutation ftest lift_score mcnemar_table mcnemar_tables mcnemar paired_ttest_5x2cv paired_ttest_kfold_cv paired_ttest_resampled permutation_test PredefinedHoldoutSplit proportion_difference RandomHoldoutSplit scoring feature_extraction LinearDiscriminantAnalysis PrincipalComponentAnalysis RBFKernelPCA feature_selection ColumnSelector ExhaustiveFeatureSelector SequentialFeatureSelector file_io find_filegroups find_files frequent_patterns apriori association_rules fpgrowth fpmax general concepts activation-functions gradient-optimization linear-gradient-derivative regularization-linear image extract_face_landmarks math num_combinations num_permutations plotting category_scatter checkerboard_plot ecdf enrichment_plot heatmap plot_confusion_matrix plot_pca_correlation_graph plot_decision_regions plot_learning_curves plot_linear_regression plot_sequential_feature_selection scatterplotmatrix stacked_barplot preprocessing CopyTransformer DenseTransformer MeanCenterer minmax_scaling one-hot_encoding shuffle_arrays_unison standardize TransactionEncoder regressor LinearRegression StackingCVRegressor StackingRegressor text generalize_names generalize_names_duplcheck tokenizer utils Counter","title":"User Guide Index"},{"location":"USER_GUIDE_INDEX/#user-guide-index","text":"","title":"User Guide Index"},{"location":"USER_GUIDE_INDEX/#classifier","text":"Adaline EnsembleVoteClassifier LogisticRegression MultiLayerPerceptron Perceptron SoftmaxRegression StackingClassifier StackingCVClassifier","title":"classifier"},{"location":"USER_GUIDE_INDEX/#cluster","text":"Kmeans","title":"cluster"},{"location":"USER_GUIDE_INDEX/#data","text":"autompg_data boston_housing_data iris_data loadlocal_mnist make_multiplexer_dataset mnist_data three_blobs_data wine_data","title":"data"},{"location":"USER_GUIDE_INDEX/#evaluate","text":"accuracy_score bias_variance_decomp bootstrap bootstrap_point632_score BootstrapOutOfBag cochrans_q confusion_matrix combined_ftest_5x2cv feature_importance_permutation ftest lift_score mcnemar_table mcnemar_tables mcnemar paired_ttest_5x2cv paired_ttest_kfold_cv paired_ttest_resampled permutation_test PredefinedHoldoutSplit proportion_difference RandomHoldoutSplit scoring","title":"evaluate"},{"location":"USER_GUIDE_INDEX/#feature_extraction","text":"LinearDiscriminantAnalysis PrincipalComponentAnalysis RBFKernelPCA","title":"feature_extraction"},{"location":"USER_GUIDE_INDEX/#feature_selection","text":"ColumnSelector ExhaustiveFeatureSelector SequentialFeatureSelector","title":"feature_selection"},{"location":"USER_GUIDE_INDEX/#file_io","text":"find_filegroups find_files","title":"file_io"},{"location":"USER_GUIDE_INDEX/#frequent_patterns","text":"apriori association_rules fpgrowth fpmax","title":"frequent_patterns"},{"location":"USER_GUIDE_INDEX/#general-concepts","text":"activation-functions gradient-optimization linear-gradient-derivative regularization-linear","title":"general concepts"},{"location":"USER_GUIDE_INDEX/#image","text":"extract_face_landmarks","title":"image"},{"location":"USER_GUIDE_INDEX/#math","text":"num_combinations num_permutations","title":"math"},{"location":"USER_GUIDE_INDEX/#plotting","text":"category_scatter checkerboard_plot ecdf enrichment_plot heatmap plot_confusion_matrix plot_pca_correlation_graph plot_decision_regions plot_learning_curves plot_linear_regression plot_sequential_feature_selection scatterplotmatrix stacked_barplot","title":"plotting"},{"location":"USER_GUIDE_INDEX/#preprocessing","text":"CopyTransformer DenseTransformer MeanCenterer minmax_scaling one-hot_encoding shuffle_arrays_unison standardize TransactionEncoder","title":"preprocessing"},{"location":"USER_GUIDE_INDEX/#regressor","text":"LinearRegression StackingCVRegressor StackingRegressor","title":"regressor"},{"location":"USER_GUIDE_INDEX/#text","text":"generalize_names generalize_names_duplcheck tokenizer","title":"text"},{"location":"USER_GUIDE_INDEX/#utils","text":"Counter","title":"utils"},{"location":"cite/","text":"Citing mlearner","title":"Citing mlearner"},{"location":"cite/#citing-mlearner","text":"","title":"Citing mlearner"},{"location":"contributors/","text":"Contributors For the current list of contributors to mlearner, please see the GitHub contributor page at [https://github.com/jaisenbe58r/MLearner/graphs/contributors].","title":"Contributors"},{"location":"contributors/#contributors","text":"For the current list of contributors to mlearner, please see the GitHub contributor page at [https://github.com/jaisenbe58r/MLearner/graphs/contributors].","title":"Contributors"},{"location":"discuss/","text":"Discuss Any questions or comments about mlearner? Join the mlearner mailing list on Google Groups!","title":"Discuss"},{"location":"discuss/#discuss","text":"Any questions or comments about mlearner? Join the mlearner mailing list on Google Groups!","title":"Discuss"},{"location":"installation/","text":"Installing mlearner PyPI To install mlearner, just execute pip install mlearner Alternatively, you download the package manually from the Python Package Index https://pypi.python.org/pypi/mlearner , unzip it, navigate into the package, and use the command: python setup.py install Upgrading via pip To upgrade an existing version of mlearner from PyPI, execute pip install mlearner --upgrade --no-deps Please note that the dependencies (NumPy and SciPy) will also be upgraded if you omit the --no-deps flag; use the --no-deps (\"no dependencies\") flag if you don't want this. Installing mlearner from the source distribution In rare cases, users reported problems on certain systems with the default pip installation command, which installs mlearner from the binary distribution (\"wheels\") on PyPI. If you should encounter similar problems, you could try to install mlearner from the source distribution instead via pip install --no-binary :all: mlearner Also, I would appreciate it if you could report any issues that occur when using pip install mlearner in hope that we can fix these in future releases. Conda The mlearner package is also available through conda forge . To install mlearner using conda, use the following command: conda install mlearner --channel conda-forge or simply conda install mlearner if you added conda-forge to your channels ( conda config --add channels conda-forge ). Dev Version The mlearner version on PyPI may always one step behind; you can install the latest development version from the GitHub repository by executing pip install git+git://github.com/rasbt/mlearner.git Or, you can fork the GitHub repository from https://github.com/jaisenbe58r/MLearner and install mlearner from your local drive via python setup.py install","title":"Installation"},{"location":"installation/#installing-mlearner","text":"","title":"Installing mlearner"},{"location":"installation/#pypi","text":"To install mlearner, just execute pip install mlearner Alternatively, you download the package manually from the Python Package Index https://pypi.python.org/pypi/mlearner , unzip it, navigate into the package, and use the command: python setup.py install","title":"PyPI"},{"location":"installation/#upgrading-via-pip","text":"To upgrade an existing version of mlearner from PyPI, execute pip install mlearner --upgrade --no-deps Please note that the dependencies (NumPy and SciPy) will also be upgraded if you omit the --no-deps flag; use the --no-deps (\"no dependencies\") flag if you don't want this.","title":"Upgrading via pip"},{"location":"installation/#installing-mlearner-from-the-source-distribution","text":"In rare cases, users reported problems on certain systems with the default pip installation command, which installs mlearner from the binary distribution (\"wheels\") on PyPI. If you should encounter similar problems, you could try to install mlearner from the source distribution instead via pip install --no-binary :all: mlearner Also, I would appreciate it if you could report any issues that occur when using pip install mlearner in hope that we can fix these in future releases.","title":"Installing mlearner from the source distribution"},{"location":"installation/#conda","text":"The mlearner package is also available through conda forge . To install mlearner using conda, use the following command: conda install mlearner --channel conda-forge or simply conda install mlearner if you added conda-forge to your channels ( conda config --add channels conda-forge ).","title":"Conda"},{"location":"installation/#dev-version","text":"The mlearner version on PyPI may always one step behind; you can install the latest development version from the GitHub repository by executing pip install git+git://github.com/rasbt/mlearner.git Or, you can fork the GitHub repository from https://github.com/jaisenbe58r/MLearner and install mlearner from your local drive via python setup.py install","title":"Dev Version"},{"location":"license/","text":"This project is released under a permissive new BSD open source license and commercially usable. There is no warranty; not even for merchantability or fitness for a particular purpose. In addition, you may use, copy, modify, and redistribute all artistic creative works (figures and images) included in this distribution under the directory according to the terms and conditions of the Creative Commons Attribution 4.0 International License. (Computer-generated graphics such as the plots produced by matplotlib fall under the BSD license mentioned above). new BSD License New BSD License Copyright (c) 2014-2020, Sebastian Raschka. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of mlearner nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Creative Commons Attribution 4.0 International License mlearner documentation figures are licensed under a Creative Commons Attribution 4.0 International License. http://creativecommons.org/licenses/by-sa/4.0/ . You are free to: Share \u2014 copy and redistribute the material in any medium or format Adapt \u2014 remix, transform, and build upon the material for any purpose, even commercially. The licensor cannot revoke these freedoms as long as you follow the license terms. Under the following terms: Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.","title":"License"},{"location":"license/#new-bsd-license","text":"New BSD License Copyright (c) 2014-2020, Sebastian Raschka. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. Neither the name of mlearner nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.","title":"new BSD License"},{"location":"license/#creative-commons-attribution-40-international-license","text":"mlearner documentation figures are licensed under a Creative Commons Attribution 4.0 International License. http://creativecommons.org/licenses/by-sa/4.0/ .","title":"Creative Commons Attribution 4.0 International License"},{"location":"license/#you-are-free-to","text":"Share \u2014 copy and redistribute the material in any medium or format Adapt \u2014 remix, transform, and build upon the material for any purpose, even commercially. The licensor cannot revoke these freedoms as long as you follow the license terms.","title":"You are free to:"},{"location":"license/#under-the-following-terms","text":"Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use. No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.","title":"Under the following terms:"}]}